{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d11e1952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found file: e:\\_SoftEng\\_BeCode\\real-estate-price-predictor\\data\\ml_pre_study_metrics\\model_metrics.csv\n",
      "⚠️ Failed to display pre-study summary: attempt to get argmax of an empty sequence\n",
      "⚠️ No experiment logs found in SQLite tracker.\n"
     ]
    }
   ],
   "source": [
    "# === [0. Imports] ===\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from utils.experiment_tracker import ExperimentTracker\n",
    "from utils.constants import METRICS_DB_PATH, CLEANED_DIR\n",
    "from utils.model_evaluator import ModelEvaluator\n",
    "from utils.model_table import ModelComparativeTable\n",
    "\n",
    "# === [1. Dynamically build absolute path to pre-study CSV file] ===\n",
    "notebook_dir = os.getcwd()\n",
    "csv_relative_path = os.path.join(\"data\", \"ml_pre_study_metrics\", \"model_metrics.csv\")\n",
    "model_pre_study_path = os.path.abspath(os.path.join(notebook_dir, \"..\", \"..\", csv_relative_path))\n",
    "\n",
    "# === [2. Check that the CSV file exists before loading it] ===\n",
    "if not os.path.isfile(model_pre_study_path):\n",
    "    raise FileNotFoundError(f\"❌ File not found: {model_pre_study_path}\")\n",
    "print(f\"✅ Found file: {model_pre_study_path}\")\n",
    "\n",
    "# === [3. Try to display pre-study summary from CSV file] ===\n",
    "mcp = None\n",
    "try:\n",
    "    mcp = ModelComparativeTable()\n",
    "    \n",
    "    # Vérifie si le fichier contient des données exploitables\n",
    "    df_csv = pd.read_csv(model_pre_study_path)\n",
    "    if df_csv.empty or \"r2\" not in df_csv.columns or df_csv[\"r2\"].dropna().empty:\n",
    "        raise ValueError(\"CSV file is empty or missing valid 'r2' values.\")\n",
    "\n",
    "    mcp.display_model_summary_pre_study(model_pre_study_path)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"⚠️ Failed to display pre-study summary:\", e)\n",
    "\n",
    "# === [4. Display live summary from ExperimentTracker if available] ===\n",
    "try:\n",
    "    if mcp is not None and not mcp.df_all_evals.empty:\n",
    "        mcp.display_model_summary()\n",
    "    else:\n",
    "        print(\"⚠️ No experiment logs found in SQLite tracker.\")\n",
    "except Exception as e:\n",
    "    print(\"⚠️ Failed to display model summary:\", e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
