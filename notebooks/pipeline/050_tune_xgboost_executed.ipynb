{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e074b4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2025-06-28T23:01:45.695315",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "# Add the project root to the Python path\n",
    "project_root = os.path.abspath(\"../..\")\n",
    "sys.path.append(project_root)\n",
    "\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from utils.constants import ML_READY_DATA_FILE, TEST_MODE\n",
    "from utils.data_loader import DataLoader\n",
    "from utils.model_evaluator import ModelEvaluator\n",
    "from utils.experiment_tracker import ExperimentTracker\n",
    "from utils.model_visualizer import ModelVisualizer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Root Mean Squared Error\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "\n",
    "# Step 1: Load and clean dataset\n",
    "loader = DataLoader(ML_READY_DATA_FILE)\n",
    "df = loader.load_data()\n",
    "\n",
    "X = df.drop(columns=[\"price\"])\n",
    "y = df[\"price\"]\n",
    "\n",
    "# Remove low-variance features\n",
    "selector = VarianceThreshold(threshold=0.01)\n",
    "selector.fit(X)  # Fit the selector on the full dataset\n",
    "X_reduced = X.loc[:, selector.get_support()]\n",
    "\n",
    "# Step 3: Extract top 30 features using Random Forest\n",
    "rf_model_all = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model_all.fit(X_reduced, y)\n",
    "\n",
    "importances = rf_model_all.feature_importances_\n",
    "feature_ranking = pd.Series(importances, index=X_reduced.columns).sort_values(ascending=False)\n",
    "top_features = feature_ranking.head(30).index.tolist()\n",
    "X_top = X_reduced[top_features]\n",
    "\n",
    "# Step 4: Define Optuna tuning function\n",
    "def tune_xgboost_with_optuna(X_data, y_data, n_trials=50):\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 800),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "            \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.0, 1.0),\n",
    "            \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.0, 1.0),\n",
    "            \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 1, 10),\n",
    "            \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n",
    "        }\n",
    "        model = xgb.XGBRegressor(**params, objective=\"reg:squarederror\", random_state=42, n_jobs=-1)\n",
    "        cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        scores = -cross_val_score(model, X_data, y_data, scoring=\"neg_root_mean_squared_error\", cv=cv)\n",
    "        return scores.mean()\n",
    "\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    return study\n",
    "\n",
    "\n",
    "# Step 5: Tune and train both models\n",
    "n_trials = 3 if TEST_MODE else 50\n",
    "\n",
    "study_all = tune_xgboost_with_optuna(X_reduced, y, n_trials=n_trials)\n",
    "model_all = xgb.XGBRegressor(**study_all.best_params, objective=\"reg:squarederror\", random_state=42, n_jobs=-1)\n",
    "model_all.fit(X_reduced, y)\n",
    "y_pred_all = model_all.predict(X_reduced)\n",
    "\n",
    "study_top = tune_xgboost_with_optuna(X_top, y, n_trials=n_trials)\n",
    "model_top = xgb.XGBRegressor(**study_top.best_params, objective=\"reg:squarederror\", random_state=42, n_jobs=-1)\n",
    "model_top.fit(X_top, y)\n",
    "y_pred_top = model_top.predict(X_top)\n",
    "\n",
    "# Step 6: Evaluate models\n",
    "evaluator_all = ModelEvaluator(\"XGBoost + Optuna CV (All Features)\")\n",
    "mae_all, rmse_all, r2_all = evaluator_all.evaluate(y, y_pred_all)\n",
    "\n",
    "evaluator_top = ModelEvaluator(\"XGBoost + Optuna CV (Top RF Features)\")\n",
    "mae_top, rmse_top, r2_top = evaluator_top.evaluate(y, y_pred_top)\n",
    "\n",
    "# Step 7: Log results\n",
    "tracker = ExperimentTracker()\n",
    "df_metrics_all = tracker.log_and_get_evaluations(\n",
    "    model=\"XGBoost + Optuna CV (All Features)\",\n",
    "    experiment=\"XGBoost with Optuna (All Features)\",\n",
    "    mae=mae_all,\n",
    "    rmse=rmse_all,\n",
    "    r2=r2_all,\n",
    ")\n",
    "\n",
    "df_metrics_top = tracker.log_and_get_evaluations(\n",
    "    model=\"XGBoost + Optuna CV (Top RF Features)\",\n",
    "    experiment=\"XGBoost with Optuna (Top RF Features)\",\n",
    "    mae=mae_top,\n",
    "    rmse=rmse_top,\n",
    "    r2=r2_top,\n",
    ")\n",
    "\n",
    "# Step 8: Display evaluation summary\n",
    "print(\"Evaluation Summary (All Features):\")\n",
    "evaluator_all.display_model_summary(df_metrics_all)\n",
    "\n",
    "print(\"Evaluation Summary (Top RF Features):\")\n",
    "evaluator_top.display_model_summary(df_metrics_top)\n",
    "\n",
    "# Step 9: Visual diagnostics\n",
    "print(\"Diagnostics (All Features):\")\n",
    "visualizer_all = ModelVisualizer(model_all, X_reduced, y, model_name=\"XGBoost + Optuna CV (All Features)\")\n",
    "visualizer_all.plot_all_diagnostics()\n",
    "\n",
    "print(\"Diagnostics (Top RF Features):\")\n",
    "visualizer_top = ModelVisualizer(model_top, X_top, y, model_name=\"XGBoost + Optuna CV (Top RF Features)\")\n",
    "visualizer_top.plot_all_diagnostics()\n",
    "\n",
    "\n",
    "ModelEvaluator.plot_price_range_residuals_side_by_side(\n",
    "    y,\n",
    "    y_pred_all,\n",
    "    y_pred_top,\n",
    "    model_names=(\"XGBoost (All Features)\", \"XGBoost (Top RF Features)\")\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "ModelEvaluator.plot_shap_comparison_beeswarm(\n",
    "    model_all=model_all,\n",
    "    x_all=X_reduced,\n",
    "    model_top=model_top,\n",
    "    x_top=X_top\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc322e9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_shap_comparison_beeswarm(model_all, x_all, model_top, x_top):\n",
    "    import shap\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    explainer_all = shap.Explainer(model_all)\n",
    "    explainer_top = shap.Explainer(model_top)\n",
    "\n",
    "    shap_values_all = explainer_all(x_all)\n",
    "    shap_values_top = explainer_top(x_top)\n",
    "\n",
    "    plt.figure(figsize=(18, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    shap.plots.beeswarm(shap_values_all, max_display=15, show=False)\n",
    "    plt.title(\"SHAP Summary – All Features\", fontsize=13)\n",
    "    \n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    shap.plots.beeswarm(shap_values_top, max_display=15, show=False)\n",
    "    plt.title(\"SHAP Summary – Top RF Features\", fontsize=13)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\"\"\"\n",
    "ModelEvaluator.plot_shap_comparison_beeswarm(\n",
    "    model_all=model_all,\n",
    "    x_all=X_reduced,\n",
    "    model_top=model_top,\n",
    "    x_top=X_top\n",
    ")\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "notebooks/pipeline/050_tune_xgboost.ipynb",
   "output_path": "notebooks/pipeline/050_tune_xgboost_executed.ipynb",
   "parameters": {},
   "start_time": "2025-06-28T23:01:44.405115",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}