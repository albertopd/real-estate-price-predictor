{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30f530fc",
   "metadata": {},
   "source": [
    "# XGBoost Regression – Untuned (GPU Compatible)\n",
    "\n",
    "This notebook trains two **XGBoost regression models**:\n",
    "- One using **all high-variance features** (`VarianceThreshold`)\n",
    "- One using the **top 30 features** selected with `RandomForestRegressor`\n",
    "\n",
    "The objective is to provide a strong baseline without any hyperparameter tuning, but with GPU acceleration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9eba1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost version: 2.0.3\n",
      "GPU support detected: tree_method='gpu_hist' works.\n",
      "GPU support detected: device='cuda' works.\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "print(\"XGBoost version:\", xgb.__version__)\n",
    "\n",
    "try:\n",
    "    booster = xgb.Booster(params={'tree_method':'gpu_hist'})\n",
    "    print(\"GPU support detected: tree_method='gpu_hist' works.\")\n",
    "except Exception as e:\n",
    "    print(\"GPU support NOT detected:\", e)\n",
    "\n",
    "try:\n",
    "    booster = xgb.Booster(params={'tree_method':'hist', 'device':'cuda'})\n",
    "    print(\"GPU support detected: device='cuda' works.\")\n",
    "except Exception as e:\n",
    "    print(\"GPU support NOT detected:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03ec5243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST_MODE is OFF – full training.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_75c75 th.col_heading.level0:nth-child(5) {\n",
       "  background-color: #fff9c4;\n",
       "}\n",
       "#T_75c75 th.col_heading.level0:nth-child(6) {\n",
       "  background-color: #fff9c4;\n",
       "}\n",
       "#T_75c75 th.col_heading.level0:nth-child(7) {\n",
       "  background-color: #fff9c4;\n",
       "}\n",
       "#T_75c75 th.col_heading.level0:nth-child(8) {\n",
       "  background-color: #f9c5c0;\n",
       "}\n",
       "#T_75c75 th.col_heading.level0:nth-child(9) {\n",
       "  background-color: #f9c5c0;\n",
       "}\n",
       "#T_75c75 th.col_heading.level0:nth-child(10) {\n",
       "  background-color: #f9c5c0;\n",
       "}\n",
       "#T_75c75_row0_col0, #T_75c75_row0_col1, #T_75c75_row0_col2, #T_75c75_row0_col3, #T_75c75_row0_col4, #T_75c75_row0_col5, #T_75c75_row0_col6, #T_75c75_row0_col7, #T_75c75_row0_col8, #T_75c75_row0_col9, #T_75c75_row0_col10, #T_75c75_row0_col12, #T_75c75_row0_col14 {\n",
       "  background-color: #4caf50;\n",
       "  color: white;\n",
       "}\n",
       "#T_75c75_row0_col11 {\n",
       "  background-color: #4caf50;\n",
       "  color: white;\n",
       "  background-color: #ef9a9a;\n",
       "  color: black;\n",
       "}\n",
       "#T_75c75_row0_col13 {\n",
       "  background-color: #4caf50;\n",
       "  color: white;\n",
       "  background-color: #1565c0;\n",
       "  color: white;\n",
       "}\n",
       "#T_75c75_row1_col0, #T_75c75_row1_col1, #T_75c75_row1_col2, #T_75c75_row1_col3, #T_75c75_row1_col4, #T_75c75_row1_col5, #T_75c75_row1_col6, #T_75c75_row1_col7, #T_75c75_row1_col8, #T_75c75_row1_col9, #T_75c75_row1_col10, #T_75c75_row1_col12, #T_75c75_row1_col14 {\n",
       "  background-color: #81c784;\n",
       "  color: black;\n",
       "}\n",
       "#T_75c75_row1_col11 {\n",
       "  background-color: #81c784;\n",
       "  color: black;\n",
       "  background-color: #ef9a9a;\n",
       "  color: black;\n",
       "}\n",
       "#T_75c75_row1_col13 {\n",
       "  background-color: #81c784;\n",
       "  color: black;\n",
       "  background-color: #1565c0;\n",
       "  color: white;\n",
       "}\n",
       "#T_75c75_row2_col0, #T_75c75_row2_col1, #T_75c75_row2_col2, #T_75c75_row2_col3, #T_75c75_row2_col4, #T_75c75_row2_col5, #T_75c75_row2_col6, #T_75c75_row2_col7, #T_75c75_row2_col8, #T_75c75_row2_col9, #T_75c75_row2_col10, #T_75c75_row2_col12, #T_75c75_row2_col14 {\n",
       "  background-color: #c8e6c9;\n",
       "  color: black;\n",
       "}\n",
       "#T_75c75_row2_col11 {\n",
       "  background-color: #c8e6c9;\n",
       "  color: black;\n",
       "  background-color: #ffcc80;\n",
       "  color: black;\n",
       "}\n",
       "#T_75c75_row2_col13 {\n",
       "  background-color: #c8e6c9;\n",
       "  color: black;\n",
       "  background-color: #1565c0;\n",
       "  color: white;\n",
       "}\n",
       "#T_75c75_row3_col11 {\n",
       "  background-color: #ffcc80;\n",
       "  color: black;\n",
       "}\n",
       "#T_75c75_row3_col13 {\n",
       "  background-color: #1565c0;\n",
       "  color: white;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_75c75\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_75c75_level0_col0\" class=\"col_heading level0 col0\" >Rank</th>\n",
       "      <th id=\"T_75c75_level0_col1\" class=\"col_heading level0 col1\" >Best</th>\n",
       "      <th id=\"T_75c75_level0_col2\" class=\"col_heading level0 col2\" >timestamp</th>\n",
       "      <th id=\"T_75c75_level0_col3\" class=\"col_heading level0 col3\" >model</th>\n",
       "      <th id=\"T_75c75_level0_col4\" class=\"col_heading level0 col4\" >mae_train</th>\n",
       "      <th id=\"T_75c75_level0_col5\" class=\"col_heading level0 col5\" >rmse_train</th>\n",
       "      <th id=\"T_75c75_level0_col6\" class=\"col_heading level0 col6\" >r2_train</th>\n",
       "      <th id=\"T_75c75_level0_col7\" class=\"col_heading level0 col7\" >mae_test</th>\n",
       "      <th id=\"T_75c75_level0_col8\" class=\"col_heading level0 col8\" >rmse_test</th>\n",
       "      <th id=\"T_75c75_level0_col9\" class=\"col_heading level0 col9\" >r2_test</th>\n",
       "      <th id=\"T_75c75_level0_col10\" class=\"col_heading level0 col10\" >r2_gap</th>\n",
       "      <th id=\"T_75c75_level0_col11\" class=\"col_heading level0 col11\" >r2_gap_diagnostic</th>\n",
       "      <th id=\"T_75c75_level0_col12\" class=\"col_heading level0 col12\" >n_features</th>\n",
       "      <th id=\"T_75c75_level0_col13\" class=\"col_heading level0 col13\" >interpretation</th>\n",
       "      <th id=\"T_75c75_level0_col14\" class=\"col_heading level0 col14\" >ranking_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_75c75_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_75c75_row0_col1\" class=\"data row0 col1\" >✔</td>\n",
       "      <td id=\"T_75c75_row0_col2\" class=\"data row0 col2\" >2025-07-01 22:24:13</td>\n",
       "      <td id=\"T_75c75_row0_col3\" class=\"data row0 col3\" >XGBoost CV (Top RF Features)</td>\n",
       "      <td id=\"T_75c75_row0_col4\" class=\"data row0 col4\" >22.1 k€</td>\n",
       "      <td id=\"T_75c75_row0_col5\" class=\"data row0 col5\" >31.4 k€</td>\n",
       "      <td id=\"T_75c75_row0_col6\" class=\"data row0 col6\" >0.977413</td>\n",
       "      <td id=\"T_75c75_row0_col7\" class=\"data row0 col7\" >63.7 k€</td>\n",
       "      <td id=\"T_75c75_row0_col8\" class=\"data row0 col8\" >96.3 k€</td>\n",
       "      <td id=\"T_75c75_row0_col9\" class=\"data row0 col9\" >0.787667</td>\n",
       "      <td id=\"T_75c75_row0_col10\" class=\"data row0 col10\" >0.189746</td>\n",
       "      <td id=\"T_75c75_row0_col11\" class=\"data row0 col11\" >❌ Strong overfitting</td>\n",
       "      <td id=\"T_75c75_row0_col12\" class=\"data row0 col12\" >30</td>\n",
       "      <td id=\"T_75c75_row0_col13\" class=\"data row0 col13\" >overfitting</td>\n",
       "      <td id=\"T_75c75_row0_col14\" class=\"data row0 col14\" >-159934.167991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_75c75_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "      <td id=\"T_75c75_row1_col1\" class=\"data row1 col1\" ></td>\n",
       "      <td id=\"T_75c75_row1_col2\" class=\"data row1 col2\" >2025-07-01 22:24:13</td>\n",
       "      <td id=\"T_75c75_row1_col3\" class=\"data row1 col3\" >XGBoost CV (All Features)</td>\n",
       "      <td id=\"T_75c75_row1_col4\" class=\"data row1 col4\" >20.3 k€</td>\n",
       "      <td id=\"T_75c75_row1_col5\" class=\"data row1 col5\" >28.7 k€</td>\n",
       "      <td id=\"T_75c75_row1_col6\" class=\"data row1 col6\" >0.981173</td>\n",
       "      <td id=\"T_75c75_row1_col7\" class=\"data row1 col7\" >64.0 k€</td>\n",
       "      <td id=\"T_75c75_row1_col8\" class=\"data row1 col8\" >96.2 k€</td>\n",
       "      <td id=\"T_75c75_row1_col9\" class=\"data row1 col9\" >0.787700</td>\n",
       "      <td id=\"T_75c75_row1_col10\" class=\"data row1 col10\" >0.193473</td>\n",
       "      <td id=\"T_75c75_row1_col11\" class=\"data row1 col11\" >❌ Strong overfitting</td>\n",
       "      <td id=\"T_75c75_row1_col12\" class=\"data row1 col12\" >72</td>\n",
       "      <td id=\"T_75c75_row1_col13\" class=\"data row1 col13\" >overfitting</td>\n",
       "      <td id=\"T_75c75_row1_col14\" class=\"data row1 col14\" >-160233.170278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_75c75_row2_col0\" class=\"data row2 col0\" >3</td>\n",
       "      <td id=\"T_75c75_row2_col1\" class=\"data row2 col1\" ></td>\n",
       "      <td id=\"T_75c75_row2_col2\" class=\"data row2 col2\" >2025-07-01 22:23:31</td>\n",
       "      <td id=\"T_75c75_row2_col3\" class=\"data row2 col3\" >XGBoost CV (All Features) [Fine-Tuned v6]</td>\n",
       "      <td id=\"T_75c75_row2_col4\" class=\"data row2 col4\" >55.0 k€</td>\n",
       "      <td id=\"T_75c75_row2_col5\" class=\"data row2 col5\" >77.5 k€</td>\n",
       "      <td id=\"T_75c75_row2_col6\" class=\"data row2 col6\" >0.863050</td>\n",
       "      <td id=\"T_75c75_row2_col7\" class=\"data row2 col7\" >67.1 k€</td>\n",
       "      <td id=\"T_75c75_row2_col8\" class=\"data row2 col8\" >98.6 k€</td>\n",
       "      <td id=\"T_75c75_row2_col9\" class=\"data row2 col9\" >0.777142</td>\n",
       "      <td id=\"T_75c75_row2_col10\" class=\"data row2 col10\" >0.085908</td>\n",
       "      <td id=\"T_75c75_row2_col11\" class=\"data row2 col11\" >⚠️ Moderate overfitting</td>\n",
       "      <td id=\"T_75c75_row2_col12\" class=\"data row2 col12\" >72</td>\n",
       "      <td id=\"T_75c75_row2_col13\" class=\"data row2 col13\" >overfitting</td>\n",
       "      <td id=\"T_75c75_row2_col14\" class=\"data row2 col14\" >-165692.175438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_75c75_row3_col0\" class=\"data row3 col0\" >4</td>\n",
       "      <td id=\"T_75c75_row3_col1\" class=\"data row3 col1\" ></td>\n",
       "      <td id=\"T_75c75_row3_col2\" class=\"data row3 col2\" >2025-07-01 22:23:31</td>\n",
       "      <td id=\"T_75c75_row3_col3\" class=\"data row3 col3\" >XGBoost CV (Top RF Features) [Fine-Tuned v6]</td>\n",
       "      <td id=\"T_75c75_row3_col4\" class=\"data row3 col4\" >56.7 k€</td>\n",
       "      <td id=\"T_75c75_row3_col5\" class=\"data row3 col5\" >79.8 k€</td>\n",
       "      <td id=\"T_75c75_row3_col6\" class=\"data row3 col6\" >0.854707</td>\n",
       "      <td id=\"T_75c75_row3_col7\" class=\"data row3 col7\" >68.4 k€</td>\n",
       "      <td id=\"T_75c75_row3_col8\" class=\"data row3 col8\" >100.3 k€</td>\n",
       "      <td id=\"T_75c75_row3_col9\" class=\"data row3 col9\" >0.769638</td>\n",
       "      <td id=\"T_75c75_row3_col10\" class=\"data row3 col10\" >0.085069</td>\n",
       "      <td id=\"T_75c75_row3_col11\" class=\"data row3 col11\" >⚠️ Moderate overfitting</td>\n",
       "      <td id=\"T_75c75_row3_col12\" class=\"data row3 col12\" >30</td>\n",
       "      <td id=\"T_75c75_row3_col13\" class=\"data row3 col13\" >overfitting</td>\n",
       "      <td id=\"T_75c75_row3_col14\" class=\"data row3 col14\" >-168652.811846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1c7b128ac60>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, os\n",
    "# Add the project root to the Python path\n",
    "project_root = os.path.abspath(\"../..\")\n",
    "sys.path.append(project_root)\n",
    "\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "from utils.constants import ML_READY_DATA_FILE, TEST_MODE\n",
    "from utils.data_loader import DataLoader\n",
    "from utils.train_test_metrics_logger import TrainTestMetricsLogger\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Display current test mode status\n",
    "if TEST_MODE:\n",
    "    print(\"TEST_MODE is ON – reduced data and iterations.\")\n",
    "else:\n",
    "    print(\"TEST_MODE is OFF – full training.\")\n",
    "\n",
    "# === Load and prepare data ===\n",
    "loader = DataLoader(ML_READY_DATA_FILE)\n",
    "df = loader.load_data()\n",
    "X = df.drop(columns=[\"price\"])\n",
    "y = df[\"price\"]\n",
    "\n",
    "# === Feature selection using variance threshold ===\n",
    "selector = VarianceThreshold(threshold=0.01)\n",
    "selector.fit(X)\n",
    "X_reduced = X.loc[:, selector.get_support()]\n",
    "\n",
    "# === Select top 30 features using Random Forest importance ===\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_reduced, y)\n",
    "importances = rf.feature_importances_\n",
    "top_features = pd.Series(importances, index=X_reduced.columns).sort_values(ascending=False).head(30).index.tolist()\n",
    "X_top = X_reduced[top_features]\n",
    "\n",
    "# === Split data for all features and top features ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, test_size=0.2, random_state=42)\n",
    "X_train_top, X_test_top, _, _ = train_test_split(X_top, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# === Define XGBoost parameters ===\n",
    "use_gpu = True\n",
    "params = {\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"random_state\": 42,\n",
    "    \"n_estimators\": 100 if TEST_MODE else 400,\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"device\": \"cuda\" if use_gpu else \"cpu\",\n",
    "    \"n_jobs\": -1,\n",
    "    \"verbosity\": 2\n",
    "}\n",
    "\n",
    "# === Train XGBoost on all features ===\n",
    "model_all = xgb.XGBRegressor(**params)\n",
    "model_all.fit(X_train, y_train)\n",
    "y_pred_train_all = model_all.predict(X_train)\n",
    "y_pred_test_all = model_all.predict(X_test)\n",
    "\n",
    "# === Train XGBoost on top 30 features ===\n",
    "model_top = xgb.XGBRegressor(**params)\n",
    "model_top.fit(X_train_top, y_train)\n",
    "y_pred_train_top = model_top.predict(X_train_top)\n",
    "y_pred_test_top = model_top.predict(X_test_top)\n",
    "\n",
    "# === Define evaluation function ===\n",
    "def evaluate(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = root_mean_squared_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mae, rmse, r2\n",
    "\n",
    "# === Evaluate performance ===\n",
    "mae_train_all, rmse_train_all, r2_train_all = evaluate(y_train, y_pred_train_all)\n",
    "mae_test_all, rmse_test_all, r2_test_all = evaluate(y_test, y_pred_test_all)\n",
    "\n",
    "mae_train_top, rmse_train_top, r2_train_top = evaluate(y_train, y_pred_train_top)\n",
    "mae_test_top, rmse_test_top, r2_test_top = evaluate(y_test, y_pred_test_top)\n",
    "\n",
    "# === Initialize logger and log results ===\n",
    "logger = TrainTestMetricsLogger()\n",
    "\n",
    "logger.log(\n",
    "    model_name=f\"XGBoost CV (All Features){' [TEST]' if TEST_MODE else ''}\",\n",
    "    experiment_name=f\"XGBoost Untuned (All Features){' [TEST]' if TEST_MODE else ''}\",\n",
    "    mae_train=mae_train_all,\n",
    "    rmse_train=rmse_train_all,\n",
    "    r2_train=r2_train_all,\n",
    "    mae_test=mae_test_all,\n",
    "    rmse_test=rmse_test_all,\n",
    "    r2_test=r2_test_all,\n",
    "    data_file=ML_READY_DATA_FILE,\n",
    "    n_features=X_train.shape[1]  \n",
    ")\n",
    "\n",
    "logger.log(\n",
    "    model_name=f\"XGBoost CV (Top RF Features){' [TEST]' if TEST_MODE else ''}\",\n",
    "    experiment_name=f\"XGBoost Untuned (Top RF Features){' [TEST]' if TEST_MODE else ''}\",\n",
    "    mae_train=mae_train_top,\n",
    "    rmse_train=rmse_train_top,\n",
    "    r2_train=r2_train_top,\n",
    "    mae_test=mae_test_top,\n",
    "    rmse_test=rmse_test_top,\n",
    "    r2_test=r2_test_top,\n",
    "    data_file=ML_READY_DATA_FILE,\n",
    "    n_features=X_train_top.shape[1]  \n",
    ")\n",
    "\n",
    "# === Display summary table ===\n",
    "logger.display_table()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "426e9d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST_MODE is OFF – full training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\_SoftEng\\_BeCode\\real-estate-price-predictor\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "e:\\_SoftEng\\_BeCode\\real-estate-price-predictor\\.venv\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [23:01:25] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "e:\\_SoftEng\\_BeCode\\real-estate-price-predictor\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_31cd0 th.col_heading.level0:nth-child(5) {\n",
       "  background-color: #fff9c4;\n",
       "}\n",
       "#T_31cd0 th.col_heading.level0:nth-child(6) {\n",
       "  background-color: #fff9c4;\n",
       "}\n",
       "#T_31cd0 th.col_heading.level0:nth-child(7) {\n",
       "  background-color: #fff9c4;\n",
       "}\n",
       "#T_31cd0 th.col_heading.level0:nth-child(8) {\n",
       "  background-color: #f9c5c0;\n",
       "}\n",
       "#T_31cd0 th.col_heading.level0:nth-child(9) {\n",
       "  background-color: #f9c5c0;\n",
       "}\n",
       "#T_31cd0 th.col_heading.level0:nth-child(10) {\n",
       "  background-color: #f9c5c0;\n",
       "}\n",
       "#T_31cd0_row0_col0, #T_31cd0_row0_col1, #T_31cd0_row0_col2, #T_31cd0_row0_col3, #T_31cd0_row0_col4, #T_31cd0_row0_col5, #T_31cd0_row0_col6, #T_31cd0_row0_col7, #T_31cd0_row0_col8, #T_31cd0_row0_col9, #T_31cd0_row0_col10, #T_31cd0_row0_col12, #T_31cd0_row0_col14 {\n",
       "  background-color: #4caf50;\n",
       "  color: white;\n",
       "}\n",
       "#T_31cd0_row0_col11 {\n",
       "  background-color: #4caf50;\n",
       "  color: white;\n",
       "  background-color: #ffcc80;\n",
       "  color: black;\n",
       "}\n",
       "#T_31cd0_row0_col13 {\n",
       "  background-color: #4caf50;\n",
       "  color: white;\n",
       "  background-color: #1565c0;\n",
       "  color: white;\n",
       "}\n",
       "#T_31cd0_row1_col0, #T_31cd0_row1_col1, #T_31cd0_row1_col2, #T_31cd0_row1_col3, #T_31cd0_row1_col4, #T_31cd0_row1_col5, #T_31cd0_row1_col6, #T_31cd0_row1_col7, #T_31cd0_row1_col8, #T_31cd0_row1_col9, #T_31cd0_row1_col10, #T_31cd0_row1_col12, #T_31cd0_row1_col14, #T_31cd0_row5_col11 {\n",
       "  background-color: #81c784;\n",
       "  color: black;\n",
       "}\n",
       "#T_31cd0_row1_col11 {\n",
       "  background-color: #81c784;\n",
       "  color: black;\n",
       "  background-color: #ffcc80;\n",
       "  color: black;\n",
       "}\n",
       "#T_31cd0_row1_col13 {\n",
       "  background-color: #81c784;\n",
       "  color: black;\n",
       "  background-color: #1565c0;\n",
       "  color: white;\n",
       "}\n",
       "#T_31cd0_row2_col0, #T_31cd0_row2_col1, #T_31cd0_row2_col2, #T_31cd0_row2_col3, #T_31cd0_row2_col4, #T_31cd0_row2_col5, #T_31cd0_row2_col6, #T_31cd0_row2_col7, #T_31cd0_row2_col8, #T_31cd0_row2_col9, #T_31cd0_row2_col10, #T_31cd0_row2_col12, #T_31cd0_row2_col14 {\n",
       "  background-color: #c8e6c9;\n",
       "  color: black;\n",
       "}\n",
       "#T_31cd0_row2_col11 {\n",
       "  background-color: #c8e6c9;\n",
       "  color: black;\n",
       "  background-color: #ef9a9a;\n",
       "  color: black;\n",
       "}\n",
       "#T_31cd0_row2_col13 {\n",
       "  background-color: #c8e6c9;\n",
       "  color: black;\n",
       "  background-color: #1565c0;\n",
       "  color: white;\n",
       "}\n",
       "#T_31cd0_row3_col11 {\n",
       "  background-color: #aed581;\n",
       "  color: black;\n",
       "}\n",
       "#T_31cd0_row3_col13 {\n",
       "  background-color: #1565c0;\n",
       "  color: white;\n",
       "}\n",
       "#T_31cd0_row4_col11 {\n",
       "  background-color: #ffcc80;\n",
       "  color: black;\n",
       "}\n",
       "#T_31cd0_row4_col13, #T_31cd0_row5_col13 {\n",
       "  background-color: #1976d2;\n",
       "  color: white;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_31cd0\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_31cd0_level0_col0\" class=\"col_heading level0 col0\" >Rank</th>\n",
       "      <th id=\"T_31cd0_level0_col1\" class=\"col_heading level0 col1\" >Best</th>\n",
       "      <th id=\"T_31cd0_level0_col2\" class=\"col_heading level0 col2\" >timestamp</th>\n",
       "      <th id=\"T_31cd0_level0_col3\" class=\"col_heading level0 col3\" >model</th>\n",
       "      <th id=\"T_31cd0_level0_col4\" class=\"col_heading level0 col4\" >mae_train</th>\n",
       "      <th id=\"T_31cd0_level0_col5\" class=\"col_heading level0 col5\" >rmse_train</th>\n",
       "      <th id=\"T_31cd0_level0_col6\" class=\"col_heading level0 col6\" >r2_train</th>\n",
       "      <th id=\"T_31cd0_level0_col7\" class=\"col_heading level0 col7\" >mae_test</th>\n",
       "      <th id=\"T_31cd0_level0_col8\" class=\"col_heading level0 col8\" >rmse_test</th>\n",
       "      <th id=\"T_31cd0_level0_col9\" class=\"col_heading level0 col9\" >r2_test</th>\n",
       "      <th id=\"T_31cd0_level0_col10\" class=\"col_heading level0 col10\" >r2_gap</th>\n",
       "      <th id=\"T_31cd0_level0_col11\" class=\"col_heading level0 col11\" >r2_gap_diagnostic</th>\n",
       "      <th id=\"T_31cd0_level0_col12\" class=\"col_heading level0 col12\" >n_features</th>\n",
       "      <th id=\"T_31cd0_level0_col13\" class=\"col_heading level0 col13\" >interpretation (r2,mae_gap)</th>\n",
       "      <th id=\"T_31cd0_level0_col14\" class=\"col_heading level0 col14\" >ranking_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_31cd0_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_31cd0_row0_col1\" class=\"data row0 col1\" >✔</td>\n",
       "      <td id=\"T_31cd0_row0_col2\" class=\"data row0 col2\" >2025-07-01 23:01:26</td>\n",
       "      <td id=\"T_31cd0_row0_col3\" class=\"data row0 col3\" >XGBoost CV (All Features) [Fine-Tuned v6]</td>\n",
       "      <td id=\"T_31cd0_row0_col4\" class=\"data row0 col4\" >55.0 k€</td>\n",
       "      <td id=\"T_31cd0_row0_col5\" class=\"data row0 col5\" >77.5 k€</td>\n",
       "      <td id=\"T_31cd0_row0_col6\" class=\"data row0 col6\" >0.863050</td>\n",
       "      <td id=\"T_31cd0_row0_col7\" class=\"data row0 col7\" >67.1 k€</td>\n",
       "      <td id=\"T_31cd0_row0_col8\" class=\"data row0 col8\" >98.6 k€</td>\n",
       "      <td id=\"T_31cd0_row0_col9\" class=\"data row0 col9\" >0.777142</td>\n",
       "      <td id=\"T_31cd0_row0_col10\" class=\"data row0 col10\" >0.085908</td>\n",
       "      <td id=\"T_31cd0_row0_col11\" class=\"data row0 col11\" >Moderate overfitting</td>\n",
       "      <td id=\"T_31cd0_row0_col12\" class=\"data row0 col12\" >72.000000</td>\n",
       "      <td id=\"T_31cd0_row0_col13\" class=\"data row0 col13\" >overfitting</td>\n",
       "      <td id=\"T_31cd0_row0_col14\" class=\"data row0 col14\" >-165692.175438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_31cd0_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "      <td id=\"T_31cd0_row1_col1\" class=\"data row1 col1\" ></td>\n",
       "      <td id=\"T_31cd0_row1_col2\" class=\"data row1 col2\" >2025-07-01 23:01:26</td>\n",
       "      <td id=\"T_31cd0_row1_col3\" class=\"data row1 col3\" >XGBoost CV (Top RF Features) [Fine-Tuned v6]</td>\n",
       "      <td id=\"T_31cd0_row1_col4\" class=\"data row1 col4\" >56.7 k€</td>\n",
       "      <td id=\"T_31cd0_row1_col5\" class=\"data row1 col5\" >79.8 k€</td>\n",
       "      <td id=\"T_31cd0_row1_col6\" class=\"data row1 col6\" >0.854707</td>\n",
       "      <td id=\"T_31cd0_row1_col7\" class=\"data row1 col7\" >68.4 k€</td>\n",
       "      <td id=\"T_31cd0_row1_col8\" class=\"data row1 col8\" >100.3 k€</td>\n",
       "      <td id=\"T_31cd0_row1_col9\" class=\"data row1 col9\" >0.769638</td>\n",
       "      <td id=\"T_31cd0_row1_col10\" class=\"data row1 col10\" >0.085069</td>\n",
       "      <td id=\"T_31cd0_row1_col11\" class=\"data row1 col11\" >Moderate overfitting</td>\n",
       "      <td id=\"T_31cd0_row1_col12\" class=\"data row1 col12\" >30.000000</td>\n",
       "      <td id=\"T_31cd0_row1_col13\" class=\"data row1 col13\" >overfitting</td>\n",
       "      <td id=\"T_31cd0_row1_col14\" class=\"data row1 col14\" >-168652.811846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_31cd0_row2_col0\" class=\"data row2 col0\" >3</td>\n",
       "      <td id=\"T_31cd0_row2_col1\" class=\"data row2 col1\" ></td>\n",
       "      <td id=\"T_31cd0_row2_col2\" class=\"data row2 col2\" >2025-07-01 22:59:16</td>\n",
       "      <td id=\"T_31cd0_row2_col3\" class=\"data row2 col3\" >Random Forest (All Features)</td>\n",
       "      <td id=\"T_31cd0_row2_col4\" class=\"data row2 col4\" >26.2 k€</td>\n",
       "      <td id=\"T_31cd0_row2_col5\" class=\"data row2 col5\" >39.1 k€</td>\n",
       "      <td id=\"T_31cd0_row2_col6\" class=\"data row2 col6\" >0.965067</td>\n",
       "      <td id=\"T_31cd0_row2_col7\" class=\"data row2 col7\" >68.3 k€</td>\n",
       "      <td id=\"T_31cd0_row2_col8\" class=\"data row2 col8\" >101.4 k€</td>\n",
       "      <td id=\"T_31cd0_row2_col9\" class=\"data row2 col9\" >0.764228</td>\n",
       "      <td id=\"T_31cd0_row2_col10\" class=\"data row2 col10\" >0.200838</td>\n",
       "      <td id=\"T_31cd0_row2_col11\" class=\"data row2 col11\" >Strong overfitting</td>\n",
       "      <td id=\"T_31cd0_row2_col12\" class=\"data row2 col12\" >72.000000</td>\n",
       "      <td id=\"T_31cd0_row2_col13\" class=\"data row2 col13\" >overfitting</td>\n",
       "      <td id=\"T_31cd0_row2_col14\" class=\"data row2 col14\" >-169750.741399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_31cd0_row3_col0\" class=\"data row3 col0\" >4</td>\n",
       "      <td id=\"T_31cd0_row3_col1\" class=\"data row3 col1\" ></td>\n",
       "      <td id=\"T_31cd0_row3_col2\" class=\"data row3 col2\" >2025-07-01 22:59:08</td>\n",
       "      <td id=\"T_31cd0_row3_col3\" class=\"data row3 col3\" >Linear Regression (All Features)</td>\n",
       "      <td id=\"T_31cd0_row3_col4\" class=\"data row3 col4\" >63.7 k€</td>\n",
       "      <td id=\"T_31cd0_row3_col5\" class=\"data row3 col5\" >94.0 k€</td>\n",
       "      <td id=\"T_31cd0_row3_col6\" class=\"data row3 col6\" >0.797768</td>\n",
       "      <td id=\"T_31cd0_row3_col7\" class=\"data row3 col7\" >76.9 k€</td>\n",
       "      <td id=\"T_31cd0_row3_col8\" class=\"data row3 col8\" >109.9 k€</td>\n",
       "      <td id=\"T_31cd0_row3_col9\" class=\"data row3 col9\" >0.723019</td>\n",
       "      <td id=\"T_31cd0_row3_col10\" class=\"data row3 col10\" >0.074748</td>\n",
       "      <td id=\"T_31cd0_row3_col11\" class=\"data row3 col11\" >Good generalization</td>\n",
       "      <td id=\"T_31cd0_row3_col12\" class=\"data row3 col12\" >nan</td>\n",
       "      <td id=\"T_31cd0_row3_col13\" class=\"data row3 col13\" >overfitting</td>\n",
       "      <td id=\"T_31cd0_row3_col14\" class=\"data row3 col14\" >-186832.774354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_31cd0_row4_col0\" class=\"data row4 col0\" >5</td>\n",
       "      <td id=\"T_31cd0_row4_col1\" class=\"data row4 col1\" ></td>\n",
       "      <td id=\"T_31cd0_row4_col2\" class=\"data row4 col2\" >2025-07-01 22:59:33</td>\n",
       "      <td id=\"T_31cd0_row4_col3\" class=\"data row4 col3\" >Polynomial Regression (Degree 2)</td>\n",
       "      <td id=\"T_31cd0_row4_col4\" class=\"data row4 col4\" >66.0 k€</td>\n",
       "      <td id=\"T_31cd0_row4_col5\" class=\"data row4 col5\" >94.4 k€</td>\n",
       "      <td id=\"T_31cd0_row4_col6\" class=\"data row4 col6\" >0.795941</td>\n",
       "      <td id=\"T_31cd0_row4_col7\" class=\"data row4 col7\" >79.1 k€</td>\n",
       "      <td id=\"T_31cd0_row4_col8\" class=\"data row4 col8\" >116.2 k€</td>\n",
       "      <td id=\"T_31cd0_row4_col9\" class=\"data row4 col9\" >0.690439</td>\n",
       "      <td id=\"T_31cd0_row4_col10\" class=\"data row4 col10\" >0.105501</td>\n",
       "      <td id=\"T_31cd0_row4_col11\" class=\"data row4 col11\" >Moderate overfitting</td>\n",
       "      <td id=\"T_31cd0_row4_col12\" class=\"data row4 col12\" >72.000000</td>\n",
       "      <td id=\"T_31cd0_row4_col13\" class=\"data row4 col13\" >good generalization</td>\n",
       "      <td id=\"T_31cd0_row4_col14\" class=\"data row4 col14\" >-195341.498785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_31cd0_row5_col0\" class=\"data row5 col0\" >6</td>\n",
       "      <td id=\"T_31cd0_row5_col1\" class=\"data row5 col1\" ></td>\n",
       "      <td id=\"T_31cd0_row5_col2\" class=\"data row5 col2\" >2025-07-01 22:58:57</td>\n",
       "      <td id=\"T_31cd0_row5_col3\" class=\"data row5 col3\" >Linear Regression (All Features) CV 5-Fold</td>\n",
       "      <td id=\"T_31cd0_row5_col4\" class=\"data row5 col4\" >84.9 k€</td>\n",
       "      <td id=\"T_31cd0_row5_col5\" class=\"data row5 col5\" >119.9 k€</td>\n",
       "      <td id=\"T_31cd0_row5_col6\" class=\"data row5 col6\" >0.670367</td>\n",
       "      <td id=\"T_31cd0_row5_col7\" class=\"data row5 col7\" >84.9 k€</td>\n",
       "      <td id=\"T_31cd0_row5_col8\" class=\"data row5 col8\" >119.9 k€</td>\n",
       "      <td id=\"T_31cd0_row5_col9\" class=\"data row5 col9\" >0.670350</td>\n",
       "      <td id=\"T_31cd0_row5_col10\" class=\"data row5 col10\" >0.000017</td>\n",
       "      <td id=\"T_31cd0_row5_col11\" class=\"data row5 col11\" >Excellent generalization</td>\n",
       "      <td id=\"T_31cd0_row5_col12\" class=\"data row5 col12\" >53.000000</td>\n",
       "      <td id=\"T_31cd0_row5_col13\" class=\"data row5 col13\" >good generalization</td>\n",
       "      <td id=\"T_31cd0_row5_col14\" class=\"data row5 col14\" >-204837.913326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2176c5ee9f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, os\n",
    "# Add the project root to the Python path\n",
    "project_root = os.path.abspath(\"../..\")\n",
    "sys.path.append(project_root)\n",
    "\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "from utils.constants import ML_READY_DATA_FILE, TEST_MODE\n",
    "from utils.data_loader import DataLoader\n",
    "from utils.train_test_metrics_logger import TrainTestMetricsLogger\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "if TEST_MODE:\n",
    "    print(\"TEST_MODE is ON – reduced data and iterations.\")\n",
    "else:\n",
    "    print(\"TEST_MODE is OFF – full training.\")\n",
    "\n",
    "# === Load and prepare data ===\n",
    "loader = DataLoader(ML_READY_DATA_FILE)\n",
    "df = loader.load_data()\n",
    "X = df.drop(columns=[\"price\"])\n",
    "y = df[\"price\"]\n",
    "\n",
    "# === Feature selection using variance threshold ===\n",
    "selector = VarianceThreshold(threshold=0.01)\n",
    "selector.fit(X)\n",
    "X_reduced = X.loc[:, selector.get_support()]\n",
    "\n",
    "# === Top 30 features via Random Forest ===\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_reduced, y)\n",
    "top_features = pd.Series(rf.feature_importances_, index=X_reduced.columns).nlargest(30).index.tolist()\n",
    "X_top = X_reduced[top_features]\n",
    "\n",
    "# === Split data ===\n",
    "X_dev_all, X_test_all, y_dev_all, y_test = train_test_split(X_reduced, y, test_size=0.2, random_state=42)\n",
    "X_train_all, X_val_all, y_train_all, y_val_all = train_test_split(X_dev_all, y_dev_all, test_size=0.2, random_state=42)\n",
    "\n",
    "X_dev_top, X_test_top, _, _ = train_test_split(X_top, y, test_size=0.2, random_state=42)\n",
    "X_train_top, X_val_top, y_train_top, y_val_top = train_test_split(X_dev_top, y_dev_all, test_size=0.2, random_state=42)\n",
    "\n",
    "# === Fine-tuned XGBoost params ===\n",
    "use_gpu = True\n",
    "params = {\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"random_state\": 42,\n",
    "    \"n_estimators\": 100 if TEST_MODE else 600,\n",
    "    \"max_depth\": 4,\n",
    "    \"min_child_weight\": 6,\n",
    "    \"gamma\": 0.4,\n",
    "    \"subsample\": 0.6,\n",
    "    \"colsample_bytree\": 0.6,\n",
    "    \"reg_alpha\": 4.0,\n",
    "    \"reg_lambda\": 5.0,\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"device\": \"cuda\" if use_gpu else \"cpu\",\n",
    "    \"n_jobs\": -1,\n",
    "    \"verbosity\": 1\n",
    "}\n",
    "\n",
    "early_stopping = 10 if TEST_MODE else 50\n",
    "\n",
    "# === Train on all features ===\n",
    "model_all = xgb.XGBRegressor(**params)\n",
    "model_all.fit(\n",
    "    X_train_all, y_train_all,\n",
    "    eval_set=[(X_val_all, y_val_all)],\n",
    "    early_stopping_rounds=early_stopping,\n",
    "    verbose=False\n",
    ")\n",
    "y_pred_train_all = model_all.predict(X_train_all)\n",
    "y_pred_test_all = model_all.predict(X_test_all)\n",
    "\n",
    "# === Train on top RF features ===\n",
    "model_top = xgb.XGBRegressor(**params)\n",
    "model_top.fit(\n",
    "    X_train_top, y_train_top,\n",
    "    eval_set=[(X_val_top, y_val_top)],\n",
    "    early_stopping_rounds=early_stopping,\n",
    "    verbose=False\n",
    ")\n",
    "y_pred_train_top = model_top.predict(X_train_top)\n",
    "y_pred_test_top = model_top.predict(X_test_top)\n",
    "\n",
    "# === Evaluation ===\n",
    "def evaluate(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = root_mean_squared_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mae, rmse, r2\n",
    "\n",
    "mae_train_all, rmse_train_all, r2_train_all = evaluate(y_train_all, y_pred_train_all)\n",
    "mae_test_all, rmse_test_all, r2_test_all = evaluate(y_test, y_pred_test_all)\n",
    "\n",
    "mae_train_top, rmse_train_top, r2_train_top = evaluate(y_train_top, y_pred_train_top)\n",
    "mae_test_top, rmse_test_top, r2_test_top = evaluate(y_test, y_pred_test_top)\n",
    "\n",
    "# === Log results ===\n",
    "logger = TrainTestMetricsLogger()\n",
    "\n",
    "logger.log(\n",
    "    model_name=f\"XGBoost CV (All Features) [Fine-Tuned v6]{' [TEST]' if TEST_MODE else ''}\",\n",
    "    experiment_name=f\"XGBoost FineTuned (All Features){' [TEST]' if TEST_MODE else ''}\",\n",
    "    mae_train=mae_train_all,\n",
    "    rmse_train=rmse_train_all,\n",
    "    r2_train=r2_train_all,\n",
    "    mae_test=mae_test_all,\n",
    "    rmse_test=rmse_test_all,\n",
    "    r2_test=r2_test_all,\n",
    "    data_file=ML_READY_DATA_FILE,\n",
    "    n_features=X_train_all.shape[1]\n",
    ")\n",
    "\n",
    "logger.log(\n",
    "    model_name=f\"XGBoost CV (Top RF Features) [Fine-Tuned v6]{' [TEST]' if TEST_MODE else ''}\",\n",
    "    experiment_name=f\"XGBoost FineTuned (Top RF Features){' [TEST]' if TEST_MODE else ''}\",\n",
    "    mae_train=mae_train_top,\n",
    "    rmse_train=rmse_train_top,\n",
    "    r2_train=r2_train_top,\n",
    "    mae_test=mae_test_top,\n",
    "    rmse_test=rmse_test_top,\n",
    "    r2_test=r2_test_top,\n",
    "    data_file=ML_READY_DATA_FILE,\n",
    "    n_features=X_train_top.shape[1]\n",
    ")\n",
    "\n",
    "logger.display_table()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003ceb78",
   "metadata": {},
   "source": [
    "# 🎯 XGBoost Regression with Optuna Hyperparameter Tuning\n",
    "\n",
    "This notebook trains two XGBoost regression models on real estate data, with **hyperparameter tuning using Optuna**. It includes all stages from loading the data to model diagnostics.\n",
    "\n",
    "## Data Preparation\n",
    "\n",
    "- Load the cleaned ML-ready dataset from a CSV file using `DataLoader`.\n",
    "- Drop the target variable `price` to separate `X` and `y`.\n",
    "- Apply `VarianceThreshold` to remove low-variance features (threshold = 0.01).\n",
    "- Use a `RandomForestRegressor` to rank feature importance.\n",
    "- Select the **top 30 most important features** for one of the models.\n",
    "\n",
    "\n",
    "## Hyperparameter Tuning (Optuna)\n",
    "\n",
    "Define the function `tune_xgboost_with_optuna(...)` that:\n",
    "\n",
    "- Runs an Optuna optimization loop.\n",
    "- Evaluates model performance with **5-Fold Cross-Validation**.\n",
    "- Minimizes the **Root Mean Squared Error (RMSE)**.\n",
    "\n",
    "### Tuned Hyperparameters:\n",
    "\n",
    "- `max_depth`\n",
    "- `learning_rate`\n",
    "- `n_estimators`\n",
    "- `subsample`, `colsample_bytree`\n",
    "- `reg_alpha`, `reg_lambda`\n",
    "- `min_child_weight`, `gamma`\n",
    "\n",
    "\n",
    "\n",
    "## Train Final Models\n",
    "\n",
    "Two models are trained:\n",
    "\n",
    "- One using **all filtered features**\n",
    "- One using the **top 30 features**\n",
    "\n",
    "Each is trained using the **best parameters** found by Optuna.\n",
    "\n",
    "---\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "Models are evaluated using:\n",
    "\n",
    "- `MAE`: Mean Absolute Error  \n",
    "- `RMSE`: Root Mean Squared Error  \n",
    "- `R<sup>2</sup>`: Coefficient of determination  \n",
    "\n",
    "Results are logged with `ExperimentTracker`.\n",
    "\n",
    "\n",
    "\n",
    "## Diagnostics\n",
    "\n",
    "- Summary tables displayed with `ModelEvaluator`\n",
    "- Residuals & diagnostic plots from `ModelVisualizer`\n",
    "- Optionally, **SHAP values** can be plotted to understand feature importance\n",
    "\n",
    "\n",
    "\n",
    "## Test Mode (Optional)\n",
    "\n",
    "When `TEST_MODE = True`, the pipeline uses:\n",
    "\n",
    "- A smaller dataset  \n",
    "- Fewer Optuna trials (`n_trials = 3`)  \n",
    "\n",
    "To speed up execution and debugging.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e99dfbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 23:03:10,463] A new study created in memory with name: no-name-46f01f80-977b-4b6d-b8bc-00dadb34a9c2\n",
      "[I 2025-07-01 23:03:12,199] Trial 0 finished with value: 105934.26419840306 and parameters: {'max_depth': 3, 'learning_rate': 0.1394927383082412, 'n_estimators': 121, 'subsample': 0.6526097024473726, 'colsample_bytree': 0.6439551539161069, 'reg_alpha': 3.3105221320379807, 'reg_lambda': 2.3620142698287556, 'min_child_weight': 7.966753546444872, 'gamma': 1.4302699459385644}. Best is trial 0 with value: 105934.26419840306.\n",
      "[I 2025-07-01 23:03:16,626] Trial 1 finished with value: 98410.1995372556 and parameters: {'max_depth': 3, 'learning_rate': 0.1605337391634462, 'n_estimators': 349, 'subsample': 0.703814631273926, 'colsample_bytree': 0.6721285431799526, 'reg_alpha': 2.287965146533392, 'reg_lambda': 4.516068240740063, 'min_child_weight': 16.85066348505134, 'gamma': 4.12066634534115}. Best is trial 1 with value: 98410.1995372556.\n",
      "[I 2025-07-01 23:03:22,498] Trial 2 finished with value: 98888.30458574336 and parameters: {'max_depth': 6, 'learning_rate': 0.1573175268362698, 'n_estimators': 314, 'subsample': 0.6304107412186285, 'colsample_bytree': 0.7102310506304542, 'reg_alpha': 3.551720807689655, 'reg_lambda': 2.7024048187406327, 'min_child_weight': 8.549063454077134, 'gamma': 0.26965720616750344}. Best is trial 1 with value: 98410.1995372556.\n",
      "[I 2025-07-01 23:03:24,513] Trial 3 finished with value: 122638.19166132454 and parameters: {'max_depth': 2, 'learning_rate': 0.033043051903054274, 'n_estimators': 216, 'subsample': 0.863478312000163, 'colsample_bytree': 0.8936225043055337, 'reg_alpha': 4.41501718989808, 'reg_lambda': 4.544857668838743, 'min_child_weight': 7.038216548292395, 'gamma': 3.5466764345022046}. Best is trial 1 with value: 98410.1995372556.\n",
      "[I 2025-07-01 23:03:25,664] Trial 4 finished with value: 119946.67044548845 and parameters: {'max_depth': 2, 'learning_rate': 0.081685703831742, 'n_estimators': 101, 'subsample': 0.7210292282209817, 'colsample_bytree': 0.6795011004684076, 'reg_alpha': 1.9067450680606362, 'reg_lambda': 1.3047981446957557, 'min_child_weight': 13.377848931750657, 'gamma': 3.640575976861849}. Best is trial 1 with value: 98410.1995372556.\n",
      "[I 2025-07-01 23:03:29,155] Trial 5 finished with value: 112316.72005351412 and parameters: {'max_depth': 2, 'learning_rate': 0.05129030092372877, 'n_estimators': 336, 'subsample': 0.8065223769949178, 'colsample_bytree': 0.6813002163374402, 'reg_alpha': 1.8575565138804782, 'reg_lambda': 2.877775842983653, 'min_child_weight': 19.702245660183053, 'gamma': 0.7653860649393729}. Best is trial 1 with value: 98410.1995372556.\n",
      "[I 2025-07-01 23:03:31,450] Trial 6 finished with value: 105696.67242172352 and parameters: {'max_depth': 5, 'learning_rate': 0.05085802777127584, 'n_estimators': 124, 'subsample': 0.7669160681113147, 'colsample_bytree': 0.8678818459612068, 'reg_alpha': 4.918204278928818, 'reg_lambda': 0.3490298131842152, 'min_child_weight': 17.587767143044882, 'gamma': 2.416507616138539}. Best is trial 1 with value: 98410.1995372556.\n",
      "[I 2025-07-01 23:03:35,196] Trial 7 finished with value: 100795.79264130404 and parameters: {'max_depth': 5, 'learning_rate': 0.04821482429772946, 'n_estimators': 221, 'subsample': 0.8391890678430857, 'colsample_bytree': 0.6370021322423397, 'reg_alpha': 1.2115881947190337, 'reg_lambda': 0.5114474099268205, 'min_child_weight': 9.94132049093276, 'gamma': 2.136657942931226}. Best is trial 1 with value: 98410.1995372556.\n",
      "[I 2025-07-01 23:03:37,639] Trial 8 finished with value: 110342.63500327496 and parameters: {'max_depth': 2, 'learning_rate': 0.07951196379867591, 'n_estimators': 257, 'subsample': 0.7184230602154531, 'colsample_bytree': 0.753900432256645, 'reg_alpha': 1.103395259887076, 'reg_lambda': 2.3264197174209356, 'min_child_weight': 17.097814280378003, 'gamma': 0.24823440773048266}. Best is trial 1 with value: 98410.1995372556.\n",
      "[I 2025-07-01 23:03:40,876] Trial 9 finished with value: 97719.76266169774 and parameters: {'max_depth': 6, 'learning_rate': 0.11740947489355766, 'n_estimators': 167, 'subsample': 0.74045455827539, 'colsample_bytree': 0.6566469480879823, 'reg_alpha': 3.509726082936961, 'reg_lambda': 0.751492129922697, 'min_child_weight': 19.363476974535892, 'gamma': 0.21124732072061891}. Best is trial 9 with value: 97719.76266169774.\n",
      "[I 2025-07-01 23:03:49,712] Trial 10 finished with value: 96945.01091144144 and parameters: {'max_depth': 6, 'learning_rate': 0.12085207718172265, 'n_estimators': 485, 'subsample': 0.8927227369057563, 'colsample_bytree': 0.7763857581421618, 'reg_alpha': 0.1653349778137314, 'reg_lambda': 1.3963007500147828, 'min_child_weight': 13.274158484855288, 'gamma': 1.5814082895963688}. Best is trial 10 with value: 96945.01091144144.\n",
      "[I 2025-07-01 23:03:58,760] Trial 11 finished with value: 97723.04724084864 and parameters: {'max_depth': 6, 'learning_rate': 0.11947528064536575, 'n_estimators': 485, 'subsample': 0.78531150335, 'colsample_bytree': 0.788601621956229, 'reg_alpha': 0.11070766683293415, 'reg_lambda': 1.3333968861921843, 'min_child_weight': 13.258485503848584, 'gamma': 1.4195103217722906}. Best is trial 10 with value: 96945.01091144144.\n",
      "[I 2025-07-01 23:04:07,182] Trial 12 finished with value: 98944.29965226969 and parameters: {'max_depth': 5, 'learning_rate': 0.19821617993618396, 'n_estimators': 500, 'subsample': 0.8721140074315635, 'colsample_bytree': 0.8088447860619703, 'reg_alpha': 3.2187702332536547, 'reg_lambda': 1.312449224393571, 'min_child_weight': 10.854081862509085, 'gamma': 1.2949064926589604}. Best is trial 10 with value: 96945.01091144144.\n",
      "[I 2025-07-01 23:04:14,812] Trial 13 finished with value: 96673.24289133231 and parameters: {'max_depth': 6, 'learning_rate': 0.10388505600045257, 'n_estimators': 414, 'subsample': 0.8975857046766058, 'colsample_bytree': 0.7412529477276993, 'reg_alpha': 0.17485916843668733, 'reg_lambda': 0.11443777885173123, 'min_child_weight': 14.974145884072547, 'gamma': 2.8765949354720926}. Best is trial 13 with value: 96673.24289133231.\n",
      "[I 2025-07-01 23:04:20,967] Trial 14 finished with value: 97147.58010308884 and parameters: {'max_depth': 4, 'learning_rate': 0.09090727007177918, 'n_estimators': 423, 'subsample': 0.8878884995407041, 'colsample_bytree': 0.7395428305259136, 'reg_alpha': 0.12081559153966989, 'reg_lambda': 0.14649621768251464, 'min_child_weight': 14.844845568208548, 'gamma': 3.0735424657801946}. Best is trial 13 with value: 96673.24289133231.\n",
      "[I 2025-07-01 23:04:28,017] Trial 15 finished with value: 97062.84662723308 and parameters: {'max_depth': 5, 'learning_rate': 0.13112798327400274, 'n_estimators': 405, 'subsample': 0.8260315956358849, 'colsample_bytree': 0.8253461355377915, 'reg_alpha': 0.7924895236264757, 'reg_lambda': 3.714363083411058, 'min_child_weight': 15.190474607725706, 'gamma': 4.580038260207155}. Best is trial 13 with value: 96673.24289133231.\n",
      "[I 2025-07-01 23:04:35,923] Trial 16 finished with value: 96686.7562498981 and parameters: {'max_depth': 6, 'learning_rate': 0.1024602635613012, 'n_estimators': 427, 'subsample': 0.8995383658998866, 'colsample_bytree': 0.7633320902305699, 'reg_alpha': 0.6336620566667548, 'reg_lambda': 1.8301532514501067, 'min_child_weight': 11.702646991579758, 'gamma': 1.9720469285354527}. Best is trial 13 with value: 96673.24289133231.\n",
      "[I 2025-07-01 23:04:41,687] Trial 17 finished with value: 97268.49192584588 and parameters: {'max_depth': 4, 'learning_rate': 0.09341743995101905, 'n_estimators': 404, 'subsample': 0.8363423131848721, 'colsample_bytree': 0.736401091001909, 'reg_alpha': 0.7542320170191574, 'reg_lambda': 1.8473320628856538, 'min_child_weight': 5.092031808514848, 'gamma': 2.9278898571445153}. Best is trial 13 with value: 96673.24289133231.\n",
      "[I 2025-07-01 23:04:49,764] Trial 18 finished with value: 96077.15659864181 and parameters: {'max_depth': 6, 'learning_rate': 0.0670033126806105, 'n_estimators': 440, 'subsample': 0.898727450124452, 'colsample_bytree': 0.6041798245938147, 'reg_alpha': 1.6061145786548505, 'reg_lambda': 3.228194592697351, 'min_child_weight': 11.357145581192935, 'gamma': 2.04103904015948}. Best is trial 18 with value: 96077.15659864181.\n",
      "[I 2025-07-01 23:04:55,734] Trial 19 finished with value: 105550.79329896541 and parameters: {'max_depth': 5, 'learning_rate': 0.01748982080036235, 'n_estimators': 369, 'subsample': 0.8602841307084763, 'colsample_bytree': 0.607532942929518, 'reg_alpha': 1.5805619117122283, 'reg_lambda': 3.4598652837250103, 'min_child_weight': 14.79548569623228, 'gamma': 2.9309168967453494}. Best is trial 18 with value: 96077.15659864181.\n",
      "[I 2025-07-01 23:05:02,318] Trial 20 finished with value: 97784.24562642831 and parameters: {'max_depth': 4, 'learning_rate': 0.06646305387220892, 'n_estimators': 445, 'subsample': 0.8119386489041134, 'colsample_bytree': 0.6172750434841588, 'reg_alpha': 2.753573453094826, 'reg_lambda': 3.3076823507559805, 'min_child_weight': 9.721737455208078, 'gamma': 3.3831495103037774}. Best is trial 18 with value: 96077.15659864181.\n",
      "[I 2025-07-01 23:05:10,815] Trial 21 finished with value: 96522.56899520045 and parameters: {'max_depth': 6, 'learning_rate': 0.09685230406076159, 'n_estimators': 450, 'subsample': 0.8995961995192657, 'colsample_bytree': 0.7121867050818899, 'reg_alpha': 0.7025446942057719, 'reg_lambda': 3.9431575401349264, 'min_child_weight': 11.593919153511807, 'gamma': 1.9690041372606497}. Best is trial 18 with value: 96077.15659864181.\n",
      "[I 2025-07-01 23:05:18,751] Trial 22 finished with value: 96375.47219802008 and parameters: {'max_depth': 6, 'learning_rate': 0.06807883745733798, 'n_estimators': 443, 'subsample': 0.8561429241042183, 'colsample_bytree': 0.7141643076848134, 'reg_alpha': 1.3631520423108547, 'reg_lambda': 4.078696051460458, 'min_child_weight': 12.147270256315476, 'gamma': 2.5418155160498244}. Best is trial 18 with value: 96077.15659864181.\n",
      "[I 2025-07-01 23:05:26,921] Trial 23 finished with value: 96327.78301071268 and parameters: {'max_depth': 6, 'learning_rate': 0.0727592453121006, 'n_estimators': 461, 'subsample': 0.8551836746934841, 'colsample_bytree': 0.7053723140564968, 'reg_alpha': 1.4597558009406701, 'reg_lambda': 3.895551185578401, 'min_child_weight': 11.69101680921012, 'gamma': 2.105406975600129}. Best is trial 18 with value: 96077.15659864181.\n",
      "[I 2025-07-01 23:05:34,838] Trial 24 finished with value: 96565.63021806757 and parameters: {'max_depth': 5, 'learning_rate': 0.06507080836580038, 'n_estimators': 463, 'subsample': 0.8426586823789582, 'colsample_bytree': 0.6980633832057375, 'reg_alpha': 1.5464518301778363, 'reg_lambda': 4.878664082404491, 'min_child_weight': 9.880534345557635, 'gamma': 2.399815760531382}. Best is trial 18 with value: 96077.15659864181.\n",
      "[I 2025-07-01 23:05:41,764] Trial 25 finished with value: 99951.65429086932 and parameters: {'max_depth': 6, 'learning_rate': 0.025145401890409466, 'n_estimators': 370, 'subsample': 0.7994041732687097, 'colsample_bytree': 0.624501383252172, 'reg_alpha': 2.3953770599265463, 'reg_lambda': 4.08776891057747, 'min_child_weight': 11.781137682528058, 'gamma': 0.9434767819875525}. Best is trial 18 with value: 96077.15659864181.\n",
      "[I 2025-07-01 23:05:46,292] Trial 26 finished with value: 97881.99634833311 and parameters: {'max_depth': 5, 'learning_rate': 0.07372054289689227, 'n_estimators': 284, 'subsample': 0.8652116604585288, 'colsample_bytree': 0.6006628623166635, 'reg_alpha': 2.029832622218793, 'reg_lambda': 3.220405868406333, 'min_child_weight': 12.763821287081734, 'gamma': 1.8176011868677038}. Best is trial 18 with value: 96077.15659864181.\n",
      "[I 2025-07-01 23:05:53,397] Trial 27 finished with value: 97618.51692906771 and parameters: {'max_depth': 6, 'learning_rate': 0.0360490660481696, 'n_estimators': 394, 'subsample': 0.7661274095489825, 'colsample_bytree': 0.7223374284299321, 'reg_alpha': 1.3184951505697335, 'reg_lambda': 4.20976895834795, 'min_child_weight': 10.617054380956905, 'gamma': 2.609949628476755}. Best is trial 18 with value: 96077.15659864181.\n",
      "[I 2025-07-01 23:05:58,793] Trial 28 finished with value: 101522.55534464211 and parameters: {'max_depth': 3, 'learning_rate': 0.058596010013010964, 'n_estimators': 465, 'subsample': 0.8498947240394348, 'colsample_bytree': 0.6612719208803027, 'reg_alpha': 2.767314278253214, 'reg_lambda': 3.718479371408811, 'min_child_weight': 8.62450165447073, 'gamma': 2.2720395945539904}. Best is trial 18 with value: 96077.15659864181.\n",
      "[I 2025-07-01 23:06:05,402] Trial 29 finished with value: 97065.5976799887 and parameters: {'max_depth': 5, 'learning_rate': 0.08194532130616075, 'n_estimators': 379, 'subsample': 0.6856832235997687, 'colsample_bytree': 0.6428230283197414, 'reg_alpha': 1.6047006215611332, 'reg_lambda': 4.999036565665422, 'min_child_weight': 6.454035423793732, 'gamma': 1.1646127376333046}. Best is trial 18 with value: 96077.15659864181.\n",
      "[I 2025-07-01 23:06:13,732] Trial 30 finished with value: 97523.49561942885 and parameters: {'max_depth': 6, 'learning_rate': 0.03634482735023088, 'n_estimators': 444, 'subsample': 0.6082216190680432, 'colsample_bytree': 0.6986011348797799, 'reg_alpha': 2.1475976506993955, 'reg_lambda': 3.0480170016974895, 'min_child_weight': 13.919267684319196, 'gamma': 1.6889804652570442}. Best is trial 18 with value: 96077.15659864181.\n",
      "[I 2025-07-01 23:06:22,052] Trial 31 finished with value: 96486.11207510353 and parameters: {'max_depth': 6, 'learning_rate': 0.0929199325071565, 'n_estimators': 454, 'subsample': 0.8756067346834264, 'colsample_bytree': 0.720280664571438, 'reg_alpha': 0.9975294515897021, 'reg_lambda': 3.81352029815627, 'min_child_weight': 12.011628062997493, 'gamma': 1.9810129993668724}. Best is trial 18 with value: 96077.15659864181.\n",
      "[I 2025-07-01 23:06:31,068] Trial 32 finished with value: 96158.13188509927 and parameters: {'max_depth': 6, 'learning_rate': 0.07398423628069883, 'n_estimators': 500, 'subsample': 0.8716356599254304, 'colsample_bytree': 0.6930284787767684, 'reg_alpha': 1.002488633696462, 'reg_lambda': 4.39831616735153, 'min_child_weight': 12.01755886499063, 'gamma': 2.7358184947342705}. Best is trial 18 with value: 96077.15659864181.\n",
      "[I 2025-07-01 23:06:39,978] Trial 33 finished with value: 96165.5061023875 and parameters: {'max_depth': 6, 'learning_rate': 0.067822812311972, 'n_estimators': 500, 'subsample': 0.8228955835404602, 'colsample_bytree': 0.6890730156340331, 'reg_alpha': 1.413304239214149, 'reg_lambda': 4.429219884474822, 'min_child_weight': 10.791675970642071, 'gamma': 2.6450725975800737}. Best is trial 18 with value: 96077.15659864181.\n",
      "[I 2025-07-01 23:06:48,799] Trial 34 finished with value: 96380.25596855089 and parameters: {'max_depth': 6, 'learning_rate': 0.04471671944418332, 'n_estimators': 499, 'subsample': 0.8202020710896814, 'colsample_bytree': 0.6905560581414552, 'reg_alpha': 0.4912030700402691, 'reg_lambda': 4.5208413751248875, 'min_child_weight': 8.877163802490285, 'gamma': 3.8238432777193845}. Best is trial 18 with value: 96077.15659864181.\n",
      "[I 2025-07-01 23:06:54,276] Trial 35 finished with value: 101389.6444924501 and parameters: {'max_depth': 3, 'learning_rate': 0.059820092875847664, 'n_estimators': 476, 'subsample': 0.8723360111265342, 'colsample_bytree': 0.6610285056204136, 'reg_alpha': 1.7191166979832633, 'reg_lambda': 4.317759759222744, 'min_child_weight': 10.34252523657738, 'gamma': 3.36451864768876}. Best is trial 18 with value: 96077.15659864181.\n",
      "[I 2025-07-01 23:07:02,891] Trial 36 finished with value: 96242.89544440081 and parameters: {'max_depth': 5, 'learning_rate': 0.08393584009920049, 'n_estimators': 498, 'subsample': 0.8267806133896614, 'colsample_bytree': 0.6759527296953033, 'reg_alpha': 1.0393513549644249, 'reg_lambda': 4.695446952575359, 'min_child_weight': 8.002654739450001, 'gamma': 2.7252539014626813}. Best is trial 18 with value: 96077.15659864181.\n",
      "[I 2025-07-01 23:07:11,187] Trial 37 finished with value: 96387.64473045932 and parameters: {'max_depth': 5, 'learning_rate': 0.08253373100943316, 'n_estimators': 500, 'subsample': 0.7948712998032816, 'colsample_bytree': 0.6748865481345939, 'reg_alpha': 1.0508381601193868, 'reg_lambda': 4.737235881932927, 'min_child_weight': 8.915808556875016, 'gamma': 3.1948365951742432}. Best is trial 18 with value: 96077.15659864181.\n",
      "[I 2025-07-01 23:07:17,029] Trial 38 finished with value: 97346.99685852016 and parameters: {'max_depth': 5, 'learning_rate': 0.15784098079354697, 'n_estimators': 333, 'subsample': 0.7714181794350806, 'colsample_bytree': 0.6454815338440669, 'reg_alpha': 0.4216924496218102, 'reg_lambda': 4.418746404545482, 'min_child_weight': 6.442376841270456, 'gamma': 4.026885394231534}. Best is trial 18 with value: 96077.15659864181.\n",
      "[I 2025-07-01 23:07:25,998] Trial 39 finished with value: 98258.97591699848 and parameters: {'max_depth': 4, 'learning_rate': 0.05535297720191537, 'n_estimators': 482, 'subsample': 0.8260256251516481, 'colsample_bytree': 0.625601300615462, 'reg_alpha': 1.8171730384619533, 'reg_lambda': 4.6752088200811235, 'min_child_weight': 7.744244228878342, 'gamma': 2.641511788050988}. Best is trial 18 with value: 96077.15659864181.\n",
      "[I 2025-07-01 23:07:34,110] Trial 40 finished with value: 97341.6194151232 and parameters: {'max_depth': 5, 'learning_rate': 0.17674356713092648, 'n_estimators': 427, 'subsample': 0.8824978388223617, 'colsample_bytree': 0.6817667470767174, 'reg_alpha': 2.234827580221016, 'reg_lambda': 2.6256903669834646, 'min_child_weight': 8.002660639532648, 'gamma': 2.732062933157781}. Best is trial 18 with value: 96077.15659864181.\n",
      "[I 2025-07-01 23:07:43,239] Trial 41 finished with value: 96287.3285331839 and parameters: {'max_depth': 6, 'learning_rate': 0.07683210220308806, 'n_estimators': 475, 'subsample': 0.8473250054890334, 'colsample_bytree': 0.6958814259918165, 'reg_alpha': 1.381305700047843, 'reg_lambda': 3.6706639517203765, 'min_child_weight': 11.06220275886364, 'gamma': 2.262251691051244}. Best is trial 18 with value: 96077.15659864181.\n",
      "[I 2025-07-01 23:07:51,834] Trial 42 finished with value: 97017.07681520135 and parameters: {'max_depth': 6, 'learning_rate': 0.11310703141452753, 'n_estimators': 475, 'subsample': 0.8372009535348308, 'colsample_bytree': 0.6685350846807586, 'reg_alpha': 0.973474643217218, 'reg_lambda': 3.5320869036053417, 'min_child_weight': 11.06717564411445, 'gamma': 2.286818630021161}. Best is trial 18 with value: 96077.15659864181.\n",
      "[I 2025-07-01 23:08:00,745] Trial 43 finished with value: 96320.98667555058 and parameters: {'max_depth': 6, 'learning_rate': 0.08474506609588237, 'n_estimators': 500, 'subsample': 0.8160164209018781, 'colsample_bytree': 0.6495036499890982, 'reg_alpha': 1.3076115681977263, 'reg_lambda': 4.337752541241639, 'min_child_weight': 9.6737682283633, 'gamma': 3.2577261362279426}. Best is trial 18 with value: 96077.15659864181.\n",
      "[I 2025-07-01 23:08:08,930] Trial 44 finished with value: 96447.98731848135 and parameters: {'max_depth': 6, 'learning_rate': 0.04447834100084203, 'n_estimators': 475, 'subsample': 0.8831778106570511, 'colsample_bytree': 0.6826862727835644, 'reg_alpha': 1.9611234903193164, 'reg_lambda': 2.9358977844326195, 'min_child_weight': 13.953945050038303, 'gamma': 3.636509773957423}. Best is trial 18 with value: 96077.15659864181.\n",
      "[I 2025-07-01 23:08:15,793] Trial 45 finished with value: 96527.50944661432 and parameters: {'max_depth': 5, 'learning_rate': 0.07534196293454368, 'n_estimators': 439, 'subsample': 0.7850223730053443, 'colsample_bytree': 0.7283735524928804, 'reg_alpha': 1.1387544272369847, 'reg_lambda': 4.685987525460845, 'min_child_weight': 9.217011085879998, 'gamma': 0.5336484683640834}. Best is trial 18 with value: 96077.15659864181.\n",
      "[I 2025-07-01 23:08:21,568] Trial 46 finished with value: 96998.71202152749 and parameters: {'max_depth': 6, 'learning_rate': 0.11067536828065505, 'n_estimators': 290, 'subsample': 0.7472567186171899, 'colsample_bytree': 0.6353038946034189, 'reg_alpha': 3.896952645181355, 'reg_lambda': 3.473721158594885, 'min_child_weight': 12.60535720646498, 'gamma': 1.656650133902076}. Best is trial 18 with value: 96077.15659864181.\n",
      "[I 2025-07-01 23:08:25,351] Trial 47 finished with value: 97631.64402223336 and parameters: {'max_depth': 6, 'learning_rate': 0.08719810039222756, 'n_estimators': 198, 'subsample': 0.8465594921262853, 'colsample_bytree': 0.7563781498639683, 'reg_alpha': 0.4103160812423656, 'reg_lambda': 4.123733896166535, 'min_child_weight': 10.778243878641455, 'gamma': 2.775110232763672}. Best is trial 18 with value: 96077.15659864181.\n",
      "[I 2025-07-01 23:08:33,233] Trial 48 finished with value: 97450.49540356694 and parameters: {'max_depth': 5, 'learning_rate': 0.1467866425119167, 'n_estimators': 486, 'subsample': 0.8695175207390551, 'colsample_bytree': 0.8644489418571973, 'reg_alpha': 0.8664762488742068, 'reg_lambda': 2.4879463046741708, 'min_child_weight': 15.829912286014043, 'gamma': 2.3434918457023586}. Best is trial 18 with value: 96077.15659864181.\n",
      "[I 2025-07-01 23:08:41,762] Trial 49 finished with value: 96414.66106622582 and parameters: {'max_depth': 6, 'learning_rate': 0.05165150161974616, 'n_estimators': 463, 'subsample': 0.6640254863226895, 'colsample_bytree': 0.695774727632479, 'reg_alpha': 2.489114678690904, 'reg_lambda': 4.5333823162230935, 'min_child_weight': 7.693653357178366, 'gamma': 2.461282032112243}. Best is trial 18 with value: 96077.15659864181.\n",
      "e:\\_SoftEng\\_BeCode\\real-estate-price-predictor\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "[I 2025-07-01 23:08:43,417] A new study created in memory with name: no-name-04b33c29-f760-43b1-bf00-10c88116e350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost + Optuna CV + Early Stopping(All Features) trained and logged.\n",
      "Train R²: 0.8709, Test R²: 0.7950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-01 23:08:49,002] Trial 0 finished with value: 98190.49364765952 and parameters: {'max_depth': 5, 'learning_rate': 0.09630813272186171, 'n_estimators': 319, 'subsample': 0.885285992667767, 'colsample_bytree': 0.7675267618490318, 'reg_alpha': 4.169328590307364, 'reg_lambda': 1.3116416927264287, 'min_child_weight': 13.448707342549802, 'gamma': 4.715109384803928}. Best is trial 0 with value: 98190.49364765952.\n",
      "[I 2025-07-01 23:08:51,248] Trial 1 finished with value: 116930.09529305816 and parameters: {'max_depth': 2, 'learning_rate': 0.047125337292986264, 'n_estimators': 227, 'subsample': 0.6199355964603914, 'colsample_bytree': 0.7103920111533724, 'reg_alpha': 4.741103694460138, 'reg_lambda': 4.41428491390529, 'min_child_weight': 19.754080022077694, 'gamma': 3.2015623632223815}. Best is trial 0 with value: 98190.49364765952.\n",
      "[I 2025-07-01 23:08:52,788] Trial 2 finished with value: 110006.34184468204 and parameters: {'max_depth': 2, 'learning_rate': 0.15215427704313547, 'n_estimators': 146, 'subsample': 0.8672566018497281, 'colsample_bytree': 0.7968823160964711, 'reg_alpha': 3.155109303909159, 'reg_lambda': 3.775869882373582, 'min_child_weight': 18.589675159260757, 'gamma': 1.5358927911151332}. Best is trial 0 with value: 98190.49364765952.\n",
      "[I 2025-07-01 23:08:56,181] Trial 3 finished with value: 101254.1589598847 and parameters: {'max_depth': 3, 'learning_rate': 0.1328379405290146, 'n_estimators': 271, 'subsample': 0.688655020524599, 'colsample_bytree': 0.6960966525503814, 'reg_alpha': 1.3536276247091634, 'reg_lambda': 2.174118657958592, 'min_child_weight': 8.038138405415733, 'gamma': 2.4944905576786742}. Best is trial 0 with value: 98190.49364765952.\n",
      "[I 2025-07-01 23:09:04,578] Trial 4 finished with value: 101568.44796322886 and parameters: {'max_depth': 6, 'learning_rate': 0.196730585994817, 'n_estimators': 447, 'subsample': 0.8862886345124985, 'colsample_bytree': 0.7020190563265184, 'reg_alpha': 0.6700624830648966, 'reg_lambda': 1.2292563203428792, 'min_child_weight': 11.423439468765274, 'gamma': 0.8046968089340079}. Best is trial 0 with value: 98190.49364765952.\n",
      "[I 2025-07-01 23:09:08,336] Trial 5 finished with value: 107287.45488344067 and parameters: {'max_depth': 4, 'learning_rate': 0.02843236756032995, 'n_estimators': 270, 'subsample': 0.8367523145436968, 'colsample_bytree': 0.7663065007089205, 'reg_alpha': 1.8678172167581657, 'reg_lambda': 3.9426208664842575, 'min_child_weight': 13.48528914732348, 'gamma': 1.0025024991987275}. Best is trial 0 with value: 98190.49364765952.\n",
      "[I 2025-07-01 23:09:10,883] Trial 6 finished with value: 102594.09826145343 and parameters: {'max_depth': 3, 'learning_rate': 0.13116932928352348, 'n_estimators': 207, 'subsample': 0.6197606641478379, 'colsample_bytree': 0.7115722871872623, 'reg_alpha': 2.7251430452673926, 'reg_lambda': 1.9235338690837047, 'min_child_weight': 15.131231394960153, 'gamma': 4.078182898218323}. Best is trial 0 with value: 98190.49364765952.\n",
      "[I 2025-07-01 23:09:14,202] Trial 7 finished with value: 99097.85389694967 and parameters: {'max_depth': 6, 'learning_rate': 0.09118833326039986, 'n_estimators': 173, 'subsample': 0.7439934378375117, 'colsample_bytree': 0.8826223018303407, 'reg_alpha': 0.37461181891063156, 'reg_lambda': 0.8150025132996479, 'min_child_weight': 9.03035643741741, 'gamma': 3.7889901934908043}. Best is trial 0 with value: 98190.49364765952.\n",
      "[I 2025-07-01 23:09:16,455] Trial 8 finished with value: 138160.6139983621 and parameters: {'max_depth': 2, 'learning_rate': 0.012329372269543637, 'n_estimators': 249, 'subsample': 0.7238586540860965, 'colsample_bytree': 0.7445729042588523, 'reg_alpha': 3.126866254388462, 'reg_lambda': 0.9932888567457256, 'min_child_weight': 7.354821043050031, 'gamma': 4.0069730324946455}. Best is trial 0 with value: 98190.49364765952.\n",
      "[I 2025-07-01 23:09:22,182] Trial 9 finished with value: 100320.71468297628 and parameters: {'max_depth': 5, 'learning_rate': 0.16229526419381513, 'n_estimators': 332, 'subsample': 0.6491553922653488, 'colsample_bytree': 0.7478448272374386, 'reg_alpha': 2.0811340533884697, 'reg_lambda': 1.6022132665929083, 'min_child_weight': 10.33765110504543, 'gamma': 2.205762135367182}. Best is trial 0 with value: 98190.49364765952.\n",
      "[I 2025-07-01 23:09:28,701] Trial 10 finished with value: 98074.00573397378 and parameters: {'max_depth': 5, 'learning_rate': 0.08058693080381059, 'n_estimators': 377, 'subsample': 0.8035634409431296, 'colsample_bytree': 0.6100375391313299, 'reg_alpha': 4.814887696999378, 'reg_lambda': 0.19877576564681787, 'min_child_weight': 15.40149682253381, 'gamma': 4.896534720015275}. Best is trial 10 with value: 98074.00573397378.\n",
      "[I 2025-07-01 23:09:35,290] Trial 11 finished with value: 98211.08109442925 and parameters: {'max_depth': 5, 'learning_rate': 0.08802107239493799, 'n_estimators': 385, 'subsample': 0.8066002188274057, 'colsample_bytree': 0.6108309250692587, 'reg_alpha': 4.935189264763893, 'reg_lambda': 0.14642789290311128, 'min_child_weight': 15.919337005289995, 'gamma': 4.888833740386868}. Best is trial 10 with value: 98074.00573397378.\n",
      "[I 2025-07-01 23:09:41,383] Trial 12 finished with value: 98351.24242514014 and parameters: {'max_depth': 5, 'learning_rate': 0.06561991674938826, 'n_estimators': 355, 'subsample': 0.7991093130098692, 'colsample_bytree': 0.6228817367336106, 'reg_alpha': 3.9903144920571014, 'reg_lambda': 0.21291291906011442, 'min_child_weight': 5.23245918857341, 'gamma': 4.985847617267915}. Best is trial 10 with value: 98074.00573397378.\n",
      "[I 2025-07-01 23:09:48,517] Trial 13 finished with value: 98674.61168058109 and parameters: {'max_depth': 4, 'learning_rate': 0.06773616137441223, 'n_estimators': 480, 'subsample': 0.7885705268084633, 'colsample_bytree': 0.8364689339237479, 'reg_alpha': 4.074174927577277, 'reg_lambda': 3.207041613614596, 'min_child_weight': 16.81199019899005, 'gamma': 4.415991711219038}. Best is trial 10 with value: 98074.00573397378.\n",
      "[I 2025-07-01 23:09:55,444] Trial 14 finished with value: 98358.46096072467 and parameters: {'max_depth': 5, 'learning_rate': 0.11262176673204018, 'n_estimators': 404, 'subsample': 0.8956673931500772, 'colsample_bytree': 0.657158466435721, 'reg_alpha': 4.096518139114513, 'reg_lambda': 2.564620080354139, 'min_child_weight': 13.378586837915398, 'gamma': 3.143769685316724}. Best is trial 10 with value: 98074.00573397378.\n",
      "[I 2025-07-01 23:09:57,514] Trial 15 finished with value: 100008.41237912075 and parameters: {'max_depth': 6, 'learning_rate': 0.10444780724454186, 'n_estimators': 100, 'subsample': 0.8412487998588207, 'colsample_bytree': 0.8142031516434944, 'reg_alpha': 3.6195045505071017, 'reg_lambda': 0.610935599843605, 'min_child_weight': 14.485901906014623, 'gamma': 0.053495889259006724}. Best is trial 10 with value: 98074.00573397378.\n",
      "[I 2025-07-01 23:10:02,091] Trial 16 finished with value: 100319.60199633893 and parameters: {'max_depth': 4, 'learning_rate': 0.06204658393699815, 'n_estimators': 325, 'subsample': 0.7717925224890174, 'colsample_bytree': 0.6467933707627664, 'reg_alpha': 4.586899878261388, 'reg_lambda': 1.4884599554134814, 'min_child_weight': 17.5253747842667, 'gamma': 3.341980792940901}. Best is trial 10 with value: 98074.00573397378.\n",
      "[I 2025-07-01 23:10:08,777] Trial 17 finished with value: 98308.2847691588 and parameters: {'max_depth': 5, 'learning_rate': 0.08462170867742361, 'n_estimators': 385, 'subsample': 0.8424847642875664, 'colsample_bytree': 0.8656994470820151, 'reg_alpha': 3.4945929260553816, 'reg_lambda': 2.7634769801140813, 'min_child_weight': 11.886893012476223, 'gamma': 4.5836418913700525}. Best is trial 10 with value: 98074.00573397378.\n",
      "[I 2025-07-01 23:10:15,390] Trial 18 finished with value: 100196.18938077046 and parameters: {'max_depth': 4, 'learning_rate': 0.041827685631288844, 'n_estimators': 453, 'subsample': 0.8197860033381407, 'colsample_bytree': 0.7772855926466877, 'reg_alpha': 4.309343984487797, 'reg_lambda': 0.547941871864783, 'min_child_weight': 13.847072017997299, 'gamma': 3.680008559753125}. Best is trial 10 with value: 98074.00573397378.\n",
      "[I 2025-07-01 23:10:21,266] Trial 19 finished with value: 98385.41840806883 and parameters: {'max_depth': 6, 'learning_rate': 0.11666346195641664, 'n_estimators': 311, 'subsample': 0.8638102367615047, 'colsample_bytree': 0.6766646634401056, 'reg_alpha': 4.90206996262216, 'reg_lambda': 1.9482684694377144, 'min_child_weight': 16.40731986351504, 'gamma': 4.4233864291578}. Best is trial 10 with value: 98074.00573397378.\n",
      "[I 2025-07-01 23:10:26,271] Trial 20 finished with value: 99838.805830594 and parameters: {'max_depth': 3, 'learning_rate': 0.1671719048408138, 'n_estimators': 416, 'subsample': 0.7070025016125304, 'colsample_bytree': 0.8451750199101205, 'reg_alpha': 2.4818248377034866, 'reg_lambda': 4.919330961865938, 'min_child_weight': 10.91862182505315, 'gamma': 1.9813901035879873}. Best is trial 10 with value: 98074.00573397378.\n",
      "[I 2025-07-01 23:10:32,220] Trial 21 finished with value: 98308.75782574233 and parameters: {'max_depth': 5, 'learning_rate': 0.08815794438597277, 'n_estimators': 357, 'subsample': 0.806849514681885, 'colsample_bytree': 0.6054410042752445, 'reg_alpha': 4.987241340371251, 'reg_lambda': 0.1874065012213221, 'min_child_weight': 15.694816511599258, 'gamma': 4.965932897159569}. Best is trial 10 with value: 98074.00573397378.\n",
      "[I 2025-07-01 23:10:38,368] Trial 22 finished with value: 98301.61226548125 and parameters: {'max_depth': 5, 'learning_rate': 0.07820331478442163, 'n_estimators': 365, 'subsample': 0.76436630241399, 'colsample_bytree': 0.6333961466472505, 'reg_alpha': 4.280828044327398, 'reg_lambda': 0.12796737165400485, 'min_child_weight': 15.258173741577554, 'gamma': 4.998551479167844}. Best is trial 10 with value: 98074.00573397378.\n",
      "[I 2025-07-01 23:10:45,221] Trial 23 finished with value: 97988.18783608513 and parameters: {'max_depth': 5, 'learning_rate': 0.10150753018784245, 'n_estimators': 423, 'subsample': 0.8669096564403146, 'colsample_bytree': 0.6132159887889543, 'reg_alpha': 4.47442616858797, 'reg_lambda': 1.1302055590467353, 'min_child_weight': 17.87986380103281, 'gamma': 4.513687449927714}. Best is trial 23 with value: 97988.18783608513.\n",
      "[I 2025-07-01 23:10:51,264] Trial 24 finished with value: 98597.15843618399 and parameters: {'max_depth': 4, 'learning_rate': 0.10360161240844297, 'n_estimators': 426, 'subsample': 0.8660341535817688, 'colsample_bytree': 0.6586431603234756, 'reg_alpha': 3.6403916249732706, 'reg_lambda': 1.4010240454153249, 'min_child_weight': 17.74166088817137, 'gamma': 4.342583937626435}. Best is trial 23 with value: 97988.18783608513.\n",
      "[I 2025-07-01 23:10:56,656] Trial 25 finished with value: 99012.0254970846 and parameters: {'max_depth': 6, 'learning_rate': 0.13299422959217982, 'n_estimators': 292, 'subsample': 0.8821451131442336, 'colsample_bytree': 0.7371557160214848, 'reg_alpha': 4.576391230497991, 'reg_lambda': 1.0431907371214444, 'min_child_weight': 18.73017265286382, 'gamma': 2.788743672935305}. Best is trial 23 with value: 97988.18783608513.\n",
      "[I 2025-07-01 23:11:04,649] Trial 26 finished with value: 97821.28927448278 and parameters: {'max_depth': 5, 'learning_rate': 0.05364178725701168, 'n_estimators': 488, 'subsample': 0.8998490065138888, 'colsample_bytree': 0.6815605539856154, 'reg_alpha': 3.8336715104637, 'reg_lambda': 0.7273016675317583, 'min_child_weight': 13.18063099787305, 'gamma': 3.5912505293712464}. Best is trial 26 with value: 97821.28927448278.\n",
      "[I 2025-07-01 23:11:11,756] Trial 27 finished with value: 99129.8262883133 and parameters: {'max_depth': 4, 'learning_rate': 0.05246430418367584, 'n_estimators': 498, 'subsample': 0.8291076994081493, 'colsample_bytree': 0.6327166410809162, 'reg_alpha': 3.7956667413266207, 'reg_lambda': 0.5912205722016605, 'min_child_weight': 19.8718948676624, 'gamma': 3.4816513074613433}. Best is trial 26 with value: 97821.28927448278.\n",
      "[I 2025-07-01 23:11:19,499] Trial 28 finished with value: 99004.71631680531 and parameters: {'max_depth': 5, 'learning_rate': 0.03359384647587149, 'n_estimators': 474, 'subsample': 0.8526721133297059, 'colsample_bytree': 0.677349877571515, 'reg_alpha': 3.237405323405297, 'reg_lambda': 0.613919723685497, 'min_child_weight': 17.296872186977417, 'gamma': 4.058288381930592}. Best is trial 26 with value: 97821.28927448278.\n",
      "[I 2025-07-01 23:11:27,002] Trial 29 finished with value: 98038.91721578104 and parameters: {'max_depth': 5, 'learning_rate': 0.07411847558309533, 'n_estimators': 446, 'subsample': 0.8969110464229715, 'colsample_bytree': 0.6010536285241151, 'reg_alpha': 4.4270558338605674, 'reg_lambda': 1.7591165130517, 'min_child_weight': 13.02088665768251, 'gamma': 2.9474185346226274}. Best is trial 26 with value: 97821.28927448278.\n",
      "[I 2025-07-01 23:11:35,248] Trial 30 finished with value: 97966.4337665235 and parameters: {'max_depth': 6, 'learning_rate': 0.07212118155151195, 'n_estimators': 448, 'subsample': 0.8992578464824319, 'colsample_bytree': 0.6754446820839102, 'reg_alpha': 4.391750132285443, 'reg_lambda': 1.8356817159784165, 'min_child_weight': 12.651975531877635, 'gamma': 3.1359400344642236}. Best is trial 26 with value: 97821.28927448278.\n",
      "[I 2025-07-01 23:11:43,207] Trial 31 finished with value: 97823.98315703528 and parameters: {'max_depth': 6, 'learning_rate': 0.07101551362497296, 'n_estimators': 446, 'subsample': 0.8955764488581983, 'colsample_bytree': 0.6708701427315894, 'reg_alpha': 4.381200342190488, 'reg_lambda': 1.6722512183823748, 'min_child_weight': 12.473676070125938, 'gamma': 2.86705592040822}. Best is trial 26 with value: 97821.28927448278.\n",
      "[I 2025-07-01 23:11:51,664] Trial 32 finished with value: 97576.01081535386 and parameters: {'max_depth': 6, 'learning_rate': 0.054898729451527406, 'n_estimators': 494, 'subsample': 0.8769355171891959, 'colsample_bytree': 0.6791566166416295, 'reg_alpha': 3.876595577412141, 'reg_lambda': 2.1110560392992035, 'min_child_weight': 12.140683744041734, 'gamma': 2.8552239208328896}. Best is trial 32 with value: 97576.01081535386.\n",
      "[I 2025-07-01 23:12:00,229] Trial 33 finished with value: 97471.43668921317 and parameters: {'max_depth': 6, 'learning_rate': 0.05252095900133868, 'n_estimators': 499, 'subsample': 0.8809775246270952, 'colsample_bytree': 0.6810462668272427, 'reg_alpha': 3.902305670082438, 'reg_lambda': 2.2619468090877395, 'min_child_weight': 12.312653898103429, 'gamma': 2.5784257730491493}. Best is trial 33 with value: 97471.43668921317.\n",
      "[I 2025-07-01 23:12:09,008] Trial 34 finished with value: 97771.98769177083 and parameters: {'max_depth': 6, 'learning_rate': 0.0528301028020278, 'n_estimators': 496, 'subsample': 0.8789327731536664, 'colsample_bytree': 0.7193221237345007, 'reg_alpha': 2.8541387247046597, 'reg_lambda': 2.252180509254724, 'min_child_weight': 9.797665491383981, 'gamma': 2.5470754705189793}. Best is trial 33 with value: 97471.43668921317.\n",
      "[I 2025-07-01 23:12:17,885] Trial 35 finished with value: 100095.20132545251 and parameters: {'max_depth': 6, 'learning_rate': 0.017133280115243378, 'n_estimators': 499, 'subsample': 0.877240243342188, 'colsample_bytree': 0.7177505167684659, 'reg_alpha': 2.877600065986145, 'reg_lambda': 3.010256591464592, 'min_child_weight': 9.920642927301106, 'gamma': 1.8393867050373842}. Best is trial 33 with value: 97471.43668921317.\n",
      "[I 2025-07-01 23:12:26,315] Trial 36 finished with value: 97742.43760611668 and parameters: {'max_depth': 6, 'learning_rate': 0.053604836421830365, 'n_estimators': 475, 'subsample': 0.8543750756529765, 'colsample_bytree': 0.6954794162135705, 'reg_alpha': 3.3576261300899266, 'reg_lambda': 2.3909869883038963, 'min_child_weight': 9.394889258731498, 'gamma': 2.4948326560927843}. Best is trial 33 with value: 97471.43668921317.\n",
      "[I 2025-07-01 23:12:34,331] Trial 37 finished with value: 97801.47179784573 and parameters: {'max_depth': 6, 'learning_rate': 0.0396283520436202, 'n_estimators': 469, 'subsample': 0.8575267137342035, 'colsample_bytree': 0.7233043280934683, 'reg_alpha': 3.299905040229073, 'reg_lambda': 2.4501483357035365, 'min_child_weight': 8.587308510353946, 'gamma': 2.4981851071439087}. Best is trial 33 with value: 97471.43668921317.\n",
      "[I 2025-07-01 23:12:42,626] Trial 38 finished with value: 98441.11058894855 and parameters: {'max_depth': 6, 'learning_rate': 0.02540110886983353, 'n_estimators': 471, 'subsample': 0.8500023973154232, 'colsample_bytree': 0.6969594044729779, 'reg_alpha': 2.4080377985287202, 'reg_lambda': 2.341266201789014, 'min_child_weight': 7.031781872559799, 'gamma': 1.4774920082497451}. Best is trial 33 with value: 97471.43668921317.\n",
      "[I 2025-07-01 23:12:51,335] Trial 39 finished with value: 97729.77061915895 and parameters: {'max_depth': 6, 'learning_rate': 0.050765752081832136, 'n_estimators': 500, 'subsample': 0.8231635271000569, 'colsample_bytree': 0.7650447606829643, 'reg_alpha': 1.4379532398016164, 'reg_lambda': 3.6045664324604125, 'min_child_weight': 9.33734357513469, 'gamma': 2.255499097206473}. Best is trial 33 with value: 97471.43668921317.\n",
      "[I 2025-07-01 23:12:59,345] Trial 40 finished with value: 97714.40751308635 and parameters: {'max_depth': 6, 'learning_rate': 0.05946965983325861, 'n_estimators': 463, 'subsample': 0.8286881717878096, 'colsample_bytree': 0.7689935663060001, 'reg_alpha': 0.7358344052718477, 'reg_lambda': 3.603909121857672, 'min_child_weight': 11.37088778674301, 'gamma': 2.154928611337917}. Best is trial 33 with value: 97471.43668921317.\n",
      "[I 2025-07-01 23:13:07,324] Trial 41 finished with value: 97943.30632446047 and parameters: {'max_depth': 6, 'learning_rate': 0.05887692871884105, 'n_estimators': 465, 'subsample': 0.8250434793516778, 'colsample_bytree': 0.773981769068251, 'reg_alpha': 1.089493609709379, 'reg_lambda': 3.5823308096519217, 'min_child_weight': 11.380848654651633, 'gamma': 2.1062802871842217}. Best is trial 33 with value: 97471.43668921317.\n",
      "[I 2025-07-01 23:13:14,782] Trial 42 finished with value: 97813.32286483151 and parameters: {'max_depth': 6, 'learning_rate': 0.04425470711975721, 'n_estimators': 432, 'subsample': 0.8214099525336787, 'colsample_bytree': 0.7904563967750472, 'reg_alpha': 0.9956132160601165, 'reg_lambda': 4.113606994719355, 'min_child_weight': 9.219775677356036, 'gamma': 1.4635086836592424}. Best is trial 33 with value: 97471.43668921317.\n",
      "[I 2025-07-01 23:13:21,771] Trial 43 finished with value: 99181.88986380861 and parameters: {'max_depth': 6, 'learning_rate': 0.028523950293458243, 'n_estimators': 404, 'subsample': 0.7874957394209432, 'colsample_bytree': 0.8046624756753138, 'reg_alpha': 1.5637108543279892, 'reg_lambda': 3.159473951963866, 'min_child_weight': 10.657753324301023, 'gamma': 1.7180785198862079}. Best is trial 33 with value: 97471.43668921317.\n",
      "[I 2025-07-01 23:13:30,124] Trial 44 finished with value: 100089.66653489442 and parameters: {'max_depth': 6, 'learning_rate': 0.019741402632955596, 'n_estimators': 480, 'subsample': 0.664015231465686, 'colsample_bytree': 0.7337030881522799, 'reg_alpha': 0.9723483552075574, 'reg_lambda': 3.575714223998184, 'min_child_weight': 7.673461091368804, 'gamma': 2.2196567505245532}. Best is trial 33 with value: 97471.43668921317.\n",
      "[I 2025-07-01 23:13:38,104] Trial 45 finished with value: 98021.86233350412 and parameters: {'max_depth': 6, 'learning_rate': 0.035884367450588706, 'n_estimators': 458, 'subsample': 0.833951608300342, 'colsample_bytree': 0.7526603107898293, 'reg_alpha': 0.30474099818423017, 'reg_lambda': 2.7704581242822237, 'min_child_weight': 11.67463737467488, 'gamma': 2.3969859757580645}. Best is trial 33 with value: 97471.43668921317.\n",
      "[I 2025-07-01 23:13:41,896] Trial 46 finished with value: 98900.46317333226 and parameters: {'max_depth': 6, 'learning_rate': 0.059612384694973, 'n_estimators': 214, 'subsample': 0.876781595883678, 'colsample_bytree': 0.759513446024218, 'reg_alpha': 0.5840382899060896, 'reg_lambda': 4.332848881403995, 'min_child_weight': 8.288517339614174, 'gamma': 2.556424073470118}. Best is trial 33 with value: 97471.43668921317.\n",
      "[I 2025-07-01 23:13:45,711] Trial 47 finished with value: 110067.77645323749 and parameters: {'max_depth': 2, 'learning_rate': 0.047717469444127296, 'n_estimators': 436, 'subsample': 0.6044208030038807, 'colsample_bytree': 0.6940976930608427, 'reg_alpha': 0.11584814549788813, 'reg_lambda': 2.132220856641531, 'min_child_weight': 6.923132854431454, 'gamma': 2.7034230278783005}. Best is trial 33 with value: 97471.43668921317.\n",
      "[I 2025-07-01 23:13:54,480] Trial 48 finished with value: 98044.2570018113 and parameters: {'max_depth': 6, 'learning_rate': 0.0459121014301457, 'n_estimators': 488, 'subsample': 0.73747801305767, 'colsample_bytree': 0.7844066631911363, 'reg_alpha': 2.0334928850722855, 'reg_lambda': 3.4470893795130833, 'min_child_weight': 14.222565756139272, 'gamma': 0.9618460772926025}. Best is trial 33 with value: 97471.43668921317.\n",
      "[I 2025-07-01 23:13:58,942] Trial 49 finished with value: 100376.86235419437 and parameters: {'max_depth': 3, 'learning_rate': 0.09400288194856185, 'n_estimators': 404, 'subsample': 0.8469065298239523, 'colsample_bytree': 0.7006008281495918, 'reg_alpha': 1.6628360216343032, 'reg_lambda': 2.7067106257118274, 'min_child_weight': 9.460639941276638, 'gamma': 1.321534227595432}. Best is trial 33 with value: 97471.43668921317.\n",
      "e:\\_SoftEng\\_BeCode\\real-estate-price-predictor\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost + Optuna CV + Early Stopping(Top 30 Features) trained and logged.\n",
      "Train R²: 0.8672, Test R²: 0.7900\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d4e3f th.col_heading.level0:nth-child(5) {\n",
       "  background-color: #fff9c4;\n",
       "}\n",
       "#T_d4e3f th.col_heading.level0:nth-child(6) {\n",
       "  background-color: #fff9c4;\n",
       "}\n",
       "#T_d4e3f th.col_heading.level0:nth-child(7) {\n",
       "  background-color: #fff9c4;\n",
       "}\n",
       "#T_d4e3f th.col_heading.level0:nth-child(8) {\n",
       "  background-color: #f9c5c0;\n",
       "}\n",
       "#T_d4e3f th.col_heading.level0:nth-child(9) {\n",
       "  background-color: #f9c5c0;\n",
       "}\n",
       "#T_d4e3f th.col_heading.level0:nth-child(10) {\n",
       "  background-color: #f9c5c0;\n",
       "}\n",
       "#T_d4e3f_row0_col0, #T_d4e3f_row0_col1, #T_d4e3f_row0_col2, #T_d4e3f_row0_col3, #T_d4e3f_row0_col4, #T_d4e3f_row0_col5, #T_d4e3f_row0_col6, #T_d4e3f_row0_col7, #T_d4e3f_row0_col8, #T_d4e3f_row0_col9, #T_d4e3f_row0_col10, #T_d4e3f_row0_col12, #T_d4e3f_row0_col14 {\n",
       "  background-color: #4caf50;\n",
       "  color: white;\n",
       "}\n",
       "#T_d4e3f_row0_col11 {\n",
       "  background-color: #4caf50;\n",
       "  color: white;\n",
       "  background-color: #aed581;\n",
       "  color: black;\n",
       "}\n",
       "#T_d4e3f_row0_col13 {\n",
       "  background-color: #4caf50;\n",
       "  color: white;\n",
       "  background-color: #1565c0;\n",
       "  color: white;\n",
       "}\n",
       "#T_d4e3f_row1_col0, #T_d4e3f_row1_col1, #T_d4e3f_row1_col2, #T_d4e3f_row1_col3, #T_d4e3f_row1_col4, #T_d4e3f_row1_col5, #T_d4e3f_row1_col6, #T_d4e3f_row1_col7, #T_d4e3f_row1_col8, #T_d4e3f_row1_col9, #T_d4e3f_row1_col10, #T_d4e3f_row1_col12, #T_d4e3f_row1_col14, #T_d4e3f_row7_col11 {\n",
       "  background-color: #81c784;\n",
       "  color: black;\n",
       "}\n",
       "#T_d4e3f_row1_col11 {\n",
       "  background-color: #81c784;\n",
       "  color: black;\n",
       "  background-color: #aed581;\n",
       "  color: black;\n",
       "}\n",
       "#T_d4e3f_row1_col13 {\n",
       "  background-color: #81c784;\n",
       "  color: black;\n",
       "  background-color: #1565c0;\n",
       "  color: white;\n",
       "}\n",
       "#T_d4e3f_row2_col0, #T_d4e3f_row2_col1, #T_d4e3f_row2_col2, #T_d4e3f_row2_col3, #T_d4e3f_row2_col4, #T_d4e3f_row2_col5, #T_d4e3f_row2_col6, #T_d4e3f_row2_col7, #T_d4e3f_row2_col8, #T_d4e3f_row2_col9, #T_d4e3f_row2_col10, #T_d4e3f_row2_col12, #T_d4e3f_row2_col14 {\n",
       "  background-color: #c8e6c9;\n",
       "  color: black;\n",
       "}\n",
       "#T_d4e3f_row2_col11 {\n",
       "  background-color: #c8e6c9;\n",
       "  color: black;\n",
       "  background-color: #ffcc80;\n",
       "  color: black;\n",
       "}\n",
       "#T_d4e3f_row2_col13 {\n",
       "  background-color: #c8e6c9;\n",
       "  color: black;\n",
       "  background-color: #1565c0;\n",
       "  color: white;\n",
       "}\n",
       "#T_d4e3f_row3_col11, #T_d4e3f_row6_col11 {\n",
       "  background-color: #ffcc80;\n",
       "  color: black;\n",
       "}\n",
       "#T_d4e3f_row3_col13, #T_d4e3f_row4_col13, #T_d4e3f_row5_col13 {\n",
       "  background-color: #1565c0;\n",
       "  color: white;\n",
       "}\n",
       "#T_d4e3f_row4_col11 {\n",
       "  background-color: #ef9a9a;\n",
       "  color: black;\n",
       "}\n",
       "#T_d4e3f_row5_col11 {\n",
       "  background-color: #aed581;\n",
       "  color: black;\n",
       "}\n",
       "#T_d4e3f_row6_col13, #T_d4e3f_row7_col13 {\n",
       "  background-color: #1976d2;\n",
       "  color: white;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d4e3f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_d4e3f_level0_col0\" class=\"col_heading level0 col0\" >Rank</th>\n",
       "      <th id=\"T_d4e3f_level0_col1\" class=\"col_heading level0 col1\" >Best</th>\n",
       "      <th id=\"T_d4e3f_level0_col2\" class=\"col_heading level0 col2\" >timestamp</th>\n",
       "      <th id=\"T_d4e3f_level0_col3\" class=\"col_heading level0 col3\" >model</th>\n",
       "      <th id=\"T_d4e3f_level0_col4\" class=\"col_heading level0 col4\" >mae_train</th>\n",
       "      <th id=\"T_d4e3f_level0_col5\" class=\"col_heading level0 col5\" >rmse_train</th>\n",
       "      <th id=\"T_d4e3f_level0_col6\" class=\"col_heading level0 col6\" >r2_train</th>\n",
       "      <th id=\"T_d4e3f_level0_col7\" class=\"col_heading level0 col7\" >mae_test</th>\n",
       "      <th id=\"T_d4e3f_level0_col8\" class=\"col_heading level0 col8\" >rmse_test</th>\n",
       "      <th id=\"T_d4e3f_level0_col9\" class=\"col_heading level0 col9\" >r2_test</th>\n",
       "      <th id=\"T_d4e3f_level0_col10\" class=\"col_heading level0 col10\" >r2_gap</th>\n",
       "      <th id=\"T_d4e3f_level0_col11\" class=\"col_heading level0 col11\" >r2_gap_diagnostic</th>\n",
       "      <th id=\"T_d4e3f_level0_col12\" class=\"col_heading level0 col12\" >n_features</th>\n",
       "      <th id=\"T_d4e3f_level0_col13\" class=\"col_heading level0 col13\" >interpretation (r2,mae_gap)</th>\n",
       "      <th id=\"T_d4e3f_level0_col14\" class=\"col_heading level0 col14\" >ranking_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_d4e3f_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_d4e3f_row0_col1\" class=\"data row0 col1\" >✔</td>\n",
       "      <td id=\"T_d4e3f_row0_col2\" class=\"data row0 col2\" >2025-07-01 23:08:43</td>\n",
       "      <td id=\"T_d4e3f_row0_col3\" class=\"data row0 col3\" >XGBoost + Optuna CV + Early Stopping(All Features)</td>\n",
       "      <td id=\"T_d4e3f_row0_col4\" class=\"data row0 col4\" >51.5 k€</td>\n",
       "      <td id=\"T_d4e3f_row0_col5\" class=\"data row0 col5\" >75.1 k€</td>\n",
       "      <td id=\"T_d4e3f_row0_col6\" class=\"data row0 col6\" >0.870899</td>\n",
       "      <td id=\"T_d4e3f_row0_col7\" class=\"data row0 col7\" >63.4 k€</td>\n",
       "      <td id=\"T_d4e3f_row0_col8\" class=\"data row0 col8\" >94.6 k€</td>\n",
       "      <td id=\"T_d4e3f_row0_col9\" class=\"data row0 col9\" >0.794986</td>\n",
       "      <td id=\"T_d4e3f_row0_col10\" class=\"data row0 col10\" >0.075913</td>\n",
       "      <td id=\"T_d4e3f_row0_col11\" class=\"data row0 col11\" >Good generalization</td>\n",
       "      <td id=\"T_d4e3f_row0_col12\" class=\"data row0 col12\" >72.000000</td>\n",
       "      <td id=\"T_d4e3f_row0_col13\" class=\"data row0 col13\" >overfitting</td>\n",
       "      <td id=\"T_d4e3f_row0_col14\" class=\"data row0 col14\" >-157934.687697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_d4e3f_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "      <td id=\"T_d4e3f_row1_col1\" class=\"data row1 col1\" ></td>\n",
       "      <td id=\"T_d4e3f_row1_col2\" class=\"data row1 col2\" >2025-07-01 23:14:00</td>\n",
       "      <td id=\"T_d4e3f_row1_col3\" class=\"data row1 col3\" >XGBoost + Optuna CV + Early Stopping(Top 30 Features)</td>\n",
       "      <td id=\"T_d4e3f_row1_col4\" class=\"data row1 col4\" >52.4 k€</td>\n",
       "      <td id=\"T_d4e3f_row1_col5\" class=\"data row1 col5\" >76.1 k€</td>\n",
       "      <td id=\"T_d4e3f_row1_col6\" class=\"data row1 col6\" >0.867237</td>\n",
       "      <td id=\"T_d4e3f_row1_col7\" class=\"data row1 col7\" >64.2 k€</td>\n",
       "      <td id=\"T_d4e3f_row1_col8\" class=\"data row1 col8\" >95.7 k€</td>\n",
       "      <td id=\"T_d4e3f_row1_col9\" class=\"data row1 col9\" >0.789978</td>\n",
       "      <td id=\"T_d4e3f_row1_col10\" class=\"data row1 col10\" >0.077259</td>\n",
       "      <td id=\"T_d4e3f_row1_col11\" class=\"data row1 col11\" >Good generalization</td>\n",
       "      <td id=\"T_d4e3f_row1_col12\" class=\"data row1 col12\" >30.000000</td>\n",
       "      <td id=\"T_d4e3f_row1_col13\" class=\"data row1 col13\" >overfitting</td>\n",
       "      <td id=\"T_d4e3f_row1_col14\" class=\"data row1 col14\" >-159913.694661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_d4e3f_row2_col0\" class=\"data row2 col0\" >3</td>\n",
       "      <td id=\"T_d4e3f_row2_col1\" class=\"data row2 col1\" ></td>\n",
       "      <td id=\"T_d4e3f_row2_col2\" class=\"data row2 col2\" >2025-07-01 23:01:26</td>\n",
       "      <td id=\"T_d4e3f_row2_col3\" class=\"data row2 col3\" >XGBoost CV (All Features) [Fine-Tuned v6]</td>\n",
       "      <td id=\"T_d4e3f_row2_col4\" class=\"data row2 col4\" >55.0 k€</td>\n",
       "      <td id=\"T_d4e3f_row2_col5\" class=\"data row2 col5\" >77.5 k€</td>\n",
       "      <td id=\"T_d4e3f_row2_col6\" class=\"data row2 col6\" >0.863050</td>\n",
       "      <td id=\"T_d4e3f_row2_col7\" class=\"data row2 col7\" >67.1 k€</td>\n",
       "      <td id=\"T_d4e3f_row2_col8\" class=\"data row2 col8\" >98.6 k€</td>\n",
       "      <td id=\"T_d4e3f_row2_col9\" class=\"data row2 col9\" >0.777142</td>\n",
       "      <td id=\"T_d4e3f_row2_col10\" class=\"data row2 col10\" >0.085908</td>\n",
       "      <td id=\"T_d4e3f_row2_col11\" class=\"data row2 col11\" >Moderate overfitting</td>\n",
       "      <td id=\"T_d4e3f_row2_col12\" class=\"data row2 col12\" >72.000000</td>\n",
       "      <td id=\"T_d4e3f_row2_col13\" class=\"data row2 col13\" >overfitting</td>\n",
       "      <td id=\"T_d4e3f_row2_col14\" class=\"data row2 col14\" >-165692.175438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_d4e3f_row3_col0\" class=\"data row3 col0\" >4</td>\n",
       "      <td id=\"T_d4e3f_row3_col1\" class=\"data row3 col1\" ></td>\n",
       "      <td id=\"T_d4e3f_row3_col2\" class=\"data row3 col2\" >2025-07-01 23:01:26</td>\n",
       "      <td id=\"T_d4e3f_row3_col3\" class=\"data row3 col3\" >XGBoost CV (Top RF Features) [Fine-Tuned v6]</td>\n",
       "      <td id=\"T_d4e3f_row3_col4\" class=\"data row3 col4\" >56.7 k€</td>\n",
       "      <td id=\"T_d4e3f_row3_col5\" class=\"data row3 col5\" >79.8 k€</td>\n",
       "      <td id=\"T_d4e3f_row3_col6\" class=\"data row3 col6\" >0.854707</td>\n",
       "      <td id=\"T_d4e3f_row3_col7\" class=\"data row3 col7\" >68.4 k€</td>\n",
       "      <td id=\"T_d4e3f_row3_col8\" class=\"data row3 col8\" >100.3 k€</td>\n",
       "      <td id=\"T_d4e3f_row3_col9\" class=\"data row3 col9\" >0.769638</td>\n",
       "      <td id=\"T_d4e3f_row3_col10\" class=\"data row3 col10\" >0.085069</td>\n",
       "      <td id=\"T_d4e3f_row3_col11\" class=\"data row3 col11\" >Moderate overfitting</td>\n",
       "      <td id=\"T_d4e3f_row3_col12\" class=\"data row3 col12\" >30.000000</td>\n",
       "      <td id=\"T_d4e3f_row3_col13\" class=\"data row3 col13\" >overfitting</td>\n",
       "      <td id=\"T_d4e3f_row3_col14\" class=\"data row3 col14\" >-168652.811846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_d4e3f_row4_col0\" class=\"data row4 col0\" >5</td>\n",
       "      <td id=\"T_d4e3f_row4_col1\" class=\"data row4 col1\" ></td>\n",
       "      <td id=\"T_d4e3f_row4_col2\" class=\"data row4 col2\" >2025-07-01 22:59:16</td>\n",
       "      <td id=\"T_d4e3f_row4_col3\" class=\"data row4 col3\" >Random Forest (All Features)</td>\n",
       "      <td id=\"T_d4e3f_row4_col4\" class=\"data row4 col4\" >26.2 k€</td>\n",
       "      <td id=\"T_d4e3f_row4_col5\" class=\"data row4 col5\" >39.1 k€</td>\n",
       "      <td id=\"T_d4e3f_row4_col6\" class=\"data row4 col6\" >0.965067</td>\n",
       "      <td id=\"T_d4e3f_row4_col7\" class=\"data row4 col7\" >68.3 k€</td>\n",
       "      <td id=\"T_d4e3f_row4_col8\" class=\"data row4 col8\" >101.4 k€</td>\n",
       "      <td id=\"T_d4e3f_row4_col9\" class=\"data row4 col9\" >0.764228</td>\n",
       "      <td id=\"T_d4e3f_row4_col10\" class=\"data row4 col10\" >0.200838</td>\n",
       "      <td id=\"T_d4e3f_row4_col11\" class=\"data row4 col11\" >Strong overfitting</td>\n",
       "      <td id=\"T_d4e3f_row4_col12\" class=\"data row4 col12\" >72.000000</td>\n",
       "      <td id=\"T_d4e3f_row4_col13\" class=\"data row4 col13\" >overfitting</td>\n",
       "      <td id=\"T_d4e3f_row4_col14\" class=\"data row4 col14\" >-169750.741399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_d4e3f_row5_col0\" class=\"data row5 col0\" >6</td>\n",
       "      <td id=\"T_d4e3f_row5_col1\" class=\"data row5 col1\" ></td>\n",
       "      <td id=\"T_d4e3f_row5_col2\" class=\"data row5 col2\" >2025-07-01 22:59:08</td>\n",
       "      <td id=\"T_d4e3f_row5_col3\" class=\"data row5 col3\" >Linear Regression (All Features)</td>\n",
       "      <td id=\"T_d4e3f_row5_col4\" class=\"data row5 col4\" >63.7 k€</td>\n",
       "      <td id=\"T_d4e3f_row5_col5\" class=\"data row5 col5\" >94.0 k€</td>\n",
       "      <td id=\"T_d4e3f_row5_col6\" class=\"data row5 col6\" >0.797768</td>\n",
       "      <td id=\"T_d4e3f_row5_col7\" class=\"data row5 col7\" >76.9 k€</td>\n",
       "      <td id=\"T_d4e3f_row5_col8\" class=\"data row5 col8\" >109.9 k€</td>\n",
       "      <td id=\"T_d4e3f_row5_col9\" class=\"data row5 col9\" >0.723019</td>\n",
       "      <td id=\"T_d4e3f_row5_col10\" class=\"data row5 col10\" >0.074748</td>\n",
       "      <td id=\"T_d4e3f_row5_col11\" class=\"data row5 col11\" >Good generalization</td>\n",
       "      <td id=\"T_d4e3f_row5_col12\" class=\"data row5 col12\" >nan</td>\n",
       "      <td id=\"T_d4e3f_row5_col13\" class=\"data row5 col13\" >overfitting</td>\n",
       "      <td id=\"T_d4e3f_row5_col14\" class=\"data row5 col14\" >-186832.774354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_d4e3f_row6_col0\" class=\"data row6 col0\" >7</td>\n",
       "      <td id=\"T_d4e3f_row6_col1\" class=\"data row6 col1\" ></td>\n",
       "      <td id=\"T_d4e3f_row6_col2\" class=\"data row6 col2\" >2025-07-01 22:59:33</td>\n",
       "      <td id=\"T_d4e3f_row6_col3\" class=\"data row6 col3\" >Polynomial Regression (Degree 2)</td>\n",
       "      <td id=\"T_d4e3f_row6_col4\" class=\"data row6 col4\" >66.0 k€</td>\n",
       "      <td id=\"T_d4e3f_row6_col5\" class=\"data row6 col5\" >94.4 k€</td>\n",
       "      <td id=\"T_d4e3f_row6_col6\" class=\"data row6 col6\" >0.795941</td>\n",
       "      <td id=\"T_d4e3f_row6_col7\" class=\"data row6 col7\" >79.1 k€</td>\n",
       "      <td id=\"T_d4e3f_row6_col8\" class=\"data row6 col8\" >116.2 k€</td>\n",
       "      <td id=\"T_d4e3f_row6_col9\" class=\"data row6 col9\" >0.690439</td>\n",
       "      <td id=\"T_d4e3f_row6_col10\" class=\"data row6 col10\" >0.105501</td>\n",
       "      <td id=\"T_d4e3f_row6_col11\" class=\"data row6 col11\" >Moderate overfitting</td>\n",
       "      <td id=\"T_d4e3f_row6_col12\" class=\"data row6 col12\" >72.000000</td>\n",
       "      <td id=\"T_d4e3f_row6_col13\" class=\"data row6 col13\" >good generalization</td>\n",
       "      <td id=\"T_d4e3f_row6_col14\" class=\"data row6 col14\" >-195341.498785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_d4e3f_row7_col0\" class=\"data row7 col0\" >8</td>\n",
       "      <td id=\"T_d4e3f_row7_col1\" class=\"data row7 col1\" ></td>\n",
       "      <td id=\"T_d4e3f_row7_col2\" class=\"data row7 col2\" >2025-07-01 22:58:57</td>\n",
       "      <td id=\"T_d4e3f_row7_col3\" class=\"data row7 col3\" >Linear Regression (All Features) CV 5-Fold</td>\n",
       "      <td id=\"T_d4e3f_row7_col4\" class=\"data row7 col4\" >84.9 k€</td>\n",
       "      <td id=\"T_d4e3f_row7_col5\" class=\"data row7 col5\" >119.9 k€</td>\n",
       "      <td id=\"T_d4e3f_row7_col6\" class=\"data row7 col6\" >0.670367</td>\n",
       "      <td id=\"T_d4e3f_row7_col7\" class=\"data row7 col7\" >84.9 k€</td>\n",
       "      <td id=\"T_d4e3f_row7_col8\" class=\"data row7 col8\" >119.9 k€</td>\n",
       "      <td id=\"T_d4e3f_row7_col9\" class=\"data row7 col9\" >0.670350</td>\n",
       "      <td id=\"T_d4e3f_row7_col10\" class=\"data row7 col10\" >0.000017</td>\n",
       "      <td id=\"T_d4e3f_row7_col11\" class=\"data row7 col11\" >Excellent generalization</td>\n",
       "      <td id=\"T_d4e3f_row7_col12\" class=\"data row7 col12\" >53.000000</td>\n",
       "      <td id=\"T_d4e3f_row7_col13\" class=\"data row7 col13\" >good generalization</td>\n",
       "      <td id=\"T_d4e3f_row7_col14\" class=\"data row7 col14\" >-204837.913326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x21746196600>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "# Add the project root to the Python path\n",
    "project_root = os.path.abspath(\"../..\")\n",
    "sys.path.append(project_root)\n",
    "\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "from utils.constants import ML_READY_DATA_FILE, TEST_MODE\n",
    "from utils.data_loader import DataLoader\n",
    "from utils.train_test_metrics_logger import TrainTestMetricsLogger\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# === Load dataset ===\n",
    "loader = DataLoader(ML_READY_DATA_FILE)\n",
    "df = loader.load_data()\n",
    "\n",
    "X = df.drop(columns=[\"price\"])\n",
    "y = df[\"price\"]\n",
    "\n",
    "# === Remove low variance features ===\n",
    "selector = VarianceThreshold(threshold=0.01)\n",
    "X_reduced = X.loc[:, selector.fit(X).get_support()]\n",
    "\n",
    "# === Select top 30 important features using Random Forest ===\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_reduced, y)\n",
    "top_features = pd.Series(rf_model.feature_importances_, index=X_reduced.columns).nlargest(30).index.tolist()\n",
    "X_top = X_reduced[top_features]\n",
    "\n",
    "# === Split datasets for training/testing ===\n",
    "X_train_all, X_test_all, y_train_all, y_test_all = train_test_split(\n",
    "    X_reduced, y, test_size=0.2, random_state=42\n",
    ")\n",
    "X_train_top, X_test_top, y_train_top, y_test_top = train_test_split(\n",
    "    X_top, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# === Optuna hyperparameter tuning function ===\n",
    "use_gpu = True\n",
    "random_state = 42\n",
    "n_trials = 3 if TEST_MODE else 50\n",
    "\n",
    "def tune_xgboost_with_optuna(X_data, y_data, n_trials):\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 2, 6),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2),\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.6, 0.9),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 0.9),\n",
    "            \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.1, 5.0),\n",
    "            \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.1, 5.0),\n",
    "            \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 5, 20),\n",
    "            \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n",
    "            \"tree_method\": \"hist\",\n",
    "            \"device\": \"cuda\" if use_gpu else \"cpu\",\n",
    "            \"random_state\": random_state,\n",
    "            \"objective\": \"reg:squarederror\",\n",
    "            \"n_jobs\": -1\n",
    "        }\n",
    "        model = xgb.XGBRegressor(**params)\n",
    "        cv = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "        scores = -cross_val_score(model, X_data, y_data, scoring=\"neg_root_mean_squared_error\", cv=cv)\n",
    "        return scores.mean()\n",
    "\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    return study.best_params\n",
    "\n",
    "# === Train and evaluate function ===\n",
    "def train_and_evaluate(X_train_full, y_train_full, X_test, y_test, model_name, experiment_name):\n",
    "    # Split X_train_full into sub-train and validation for early stopping\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_full, y_train_full, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Tune with Optuna on X_train (not on X_val)\n",
    "    best_params = tune_xgboost_with_optuna(X_train, y_train, n_trials)\n",
    "\n",
    "    # Train with early stopping on validation set\n",
    "    model = xgb.XGBRegressor(**best_params)\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # Evaluate on full train and test set\n",
    "    y_pred_train = model.predict(X_train_full)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    mae_train = mean_absolute_error(y_train_full, y_pred_train)\n",
    "    rmse_train = root_mean_squared_error(y_train_full, y_pred_train)\n",
    "    r2_train = r2_score(y_train_full, y_pred_train)\n",
    "\n",
    "    mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "    rmse_test = root_mean_squared_error(y_test, y_pred_test)\n",
    "    r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "    logger.log(\n",
    "        model_name=model_name,\n",
    "        experiment_name=experiment_name,\n",
    "        mae_train=mae_train,\n",
    "        rmse_train=rmse_train,\n",
    "        r2_train=r2_train,\n",
    "        mae_test=mae_test,\n",
    "        rmse_test=rmse_test,\n",
    "        r2_test=r2_test,\n",
    "        data_file=ML_READY_DATA_FILE,\n",
    "        n_features=X_train_full.shape[1]\n",
    "    )\n",
    "\n",
    "    print(f\"{model_name} trained and logged.\")\n",
    "    print(f\"Train R²: {r2_train:.4f}, Test R²: {r2_test:.4f}\")\n",
    "\n",
    "# === Initialize logger ===\n",
    "logger = TrainTestMetricsLogger()\n",
    "\n",
    "# === Run training and logging for all features ===\n",
    "train_and_evaluate(\n",
    "    X_train_all, y_train_all, X_test_all, y_test_all,\n",
    "    model_name=\"XGBoost + Optuna CV + Early Stopping(All Features)\",\n",
    "    experiment_name=\"XGBoost + Optuna-Tuned (All Features)\"\n",
    ")\n",
    "\n",
    "# === Run training and logging for top 30 features ===\n",
    "train_and_evaluate(\n",
    "    X_train_top, y_train_top, X_test_top, y_test_top,\n",
    "    model_name=\"XGBoost + Optuna CV + Early Stopping(Top 30 Features)\",\n",
    "    experiment_name=\"XGBoost + Optuna-Tuned (Top 30 Features)\"\n",
    ")\n",
    "\n",
    "# === Display logged results ===\n",
    "logger.display_table(n_rows=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5020ea",
   "metadata": {},
   "source": [
    "# Saving XGBoost + Optuna Hyperparameter Tuning Models (`.pkl`) After Training\n",
    "\n",
    "After training XGBoost models with Optuna tuning, it's essential to persist the trained models using `.pkl` files. The script below ensures each model is saved with a unique, timestamped filename and organized in the correct directory.\n",
    "\n",
    "\n",
    "##  What the Script Does\n",
    "\n",
    "1. **Appends the project root** to the Python path (to allow relative imports).\n",
    "2. **Generates a timestamped filename**, including an optional `_TEST` suffix if `TEST_MODE` is enabled.\n",
    "3. **Ensures the target directory exists**, and creates it if necessary.\n",
    "4. **Saves both trained models** using `joblib.dump()`:\n",
    "   - One trained with **all features**.\n",
    "   - One trained with the **top 30 features** (e.g., selected via Random Forest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91008cd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T12:22:05.475416Z",
     "iopub.status.busy": "2025-06-29T12:22:05.475416Z",
     "iopub.status.idle": "2025-06-29T12:22:05.524922Z",
     "shell.execute_reply": "2025-06-29T12:22:05.524419Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✔] Models saved to 'e:\\_SoftEng\\_BeCode\\real-estate-price-predictor\\models\\pkl' as:\n",
      " - xgboost_optuna_all_20250701_1956.pkl\n",
      " - xgboost_optuna_top30_20250701_1956.pkl\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "# Add the project root to the Python path\n",
    "project_root = os.path.abspath(\"../..\")\n",
    "sys.path.append(project_root)\n",
    "\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "from utils.constants import TEST_MODE, MODELS_DIR\n",
    "\n",
    "# Create timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "# Add suffix if in TEST mode\n",
    "suffix = \"_TEST\" if TEST_MODE else \"\"\n",
    "\n",
    "# Define subdirectory for .pkl files\n",
    "PKL_DIR = os.path.join(MODELS_DIR, \"pkl\")\n",
    "os.makedirs(PKL_DIR, exist_ok=True)\n",
    "\n",
    "# Build filenames\n",
    "filename_all = f\"xgboost_optuna_all_{timestamp}{suffix}.pkl\"\n",
    "filename_top = f\"xgboost_optuna_top30_{timestamp}{suffix}.pkl\"\n",
    "\n",
    "# Save models\n",
    "joblib.dump(model_all, os.path.join(PKL_DIR, filename_all))\n",
    "joblib.dump(model_top, os.path.join(PKL_DIR, filename_top))\n",
    "\n",
    "print(f\"[✔] Models saved to '{PKL_DIR}' as:\\n - {filename_all}\\n - {filename_top}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8b065b",
   "metadata": {},
   "source": [
    "# Saving Feature Lists Used by Each Model (`.json`)\n",
    "\n",
    "After training and saving your machine learning models (e.g., XGBoost or CatBoost), it's critical to also save the **list of features** used during training. This ensures **inference compatibility** and prevents mismatches between the model and the input data.\n",
    "\n",
    "\n",
    "## What the Script Does\n",
    "\n",
    "1. **Creates the directory** for storing feature metadata:\n",
    "   - Located in: `models/features/`\n",
    "\n",
    "2. **Saves two JSON files**:\n",
    "   - One listing the full set of features used in the **all-features model**.\n",
    "   - One listing the selected **top 30 features** (e.g., based on feature importance).\n",
    "\n",
    "3. **Uses the same base name as the corresponding `.pkl` model**, replacing the extension:\n",
    "   - Example: `xgboost_optuna_all_20250629_1430.pkl` → `xgboost_optuna_all_20250629_1430.json`\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0def615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✔] Associated feature files saved to 'e:\\_SoftEng\\_BeCode\\real-estate-price-predictor\\models\\features'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Define subdirectory for features\n",
    "FEATURES_DIR = os.path.join(MODELS_DIR, \"features\")\n",
    "os.makedirs(FEATURES_DIR, exist_ok=True)\n",
    "\n",
    "# Save features used for each model\n",
    "with open(os.path.join(FEATURES_DIR, filename_all.replace(\".pkl\", \".json\")), \"w\") as f:\n",
    "    json.dump(list(X_reduced.columns), f, indent=2)\n",
    "\n",
    "with open(os.path.join(FEATURES_DIR, filename_top.replace(\".pkl\", \".json\")), \"w\") as f:\n",
    "    json.dump(top_features, f, indent=2)\n",
    "\n",
    "print(f\"[✔] Associated feature files saved to '{FEATURES_DIR}'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
